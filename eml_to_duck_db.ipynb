{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20daaedd",
   "metadata": {},
   "source": [
    "# PST to DuckDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e093b7c",
   "metadata": {},
   "source": [
    "Notebook to explore cleanly how to go from mbox file format to DuckDB database followed The Classes in models/models.py cleanly without different codes etc.\n",
    "This has to be transformed into different function files later on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8f42ca",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86343f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import mailbox\n",
    "import pandas as pd\n",
    "import email\n",
    "import os\n",
    "from email.header import decode_header\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import sqlite3\n",
    "import html\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "import duckdb\n",
    "\n",
    "import json\n",
    "import uuid\n",
    "from typing import List, Dict, Any, Optional, Tuple, Union\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcbeebc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46cbf611",
   "metadata": {},
   "source": [
    "### Importing Function & Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fcf5746",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.duckdb import setup_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54c35390",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.models import EmailAddress, MailingList, Organisation, Position, Entity, Attachment, ReceiverEmail, SenderEmail\n",
    "\n",
    "# Import Pydantic elements\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989778c4",
   "metadata": {},
   "source": [
    "### Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6a6183f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test des fonctions:\n",
    "\n",
    "mbox_single_file_path = 'data/processed/mailbox_cecile/AG.mbox'\n",
    "mbox_path = 'data/processed/mailbox_cecile/'\n",
    "TEST_SAMPLE_PATH = 'data/processed/real_test_sample/'\n",
    "db_path = 'data/database/database.duckdb'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7ed1c3",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373a7fa3",
   "metadata": {},
   "source": [
    "### Mbox/Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "441174e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_email_address(address_str):\n",
    "    \"\"\"Parse a string containing email addresses into a list of Entity objects with better error handling\"\"\"\n",
    "    if not address_str:\n",
    "        return []\n",
    "\n",
    "    entities = []\n",
    "    # Simple regex to extract name and email from patterns like \"Name <email@example.com>\"\n",
    "    email_pattern = re.compile(r'(.*?)\\s*<([^>]+)>|([^,\\s]+@[^,\\s]+)')\n",
    "\n",
    "    try:\n",
    "        # Split by commas, but handle potential nested commas in quotes\n",
    "        addresses = []\n",
    "        in_quotes = False\n",
    "        current_address = \"\"\n",
    "\n",
    "        for char in address_str:\n",
    "            if char == '\"':\n",
    "                in_quotes = not in_quotes\n",
    "                current_address += char\n",
    "            elif char == ',' and not in_quotes:\n",
    "                addresses.append(current_address.strip())\n",
    "                current_address = \"\"\n",
    "            else:\n",
    "                current_address += char\n",
    "\n",
    "        # Add the last address if there is one\n",
    "        if current_address.strip():\n",
    "            addresses.append(current_address.strip())\n",
    "\n",
    "        # If no addresses were found, try the whole string\n",
    "        if not addresses:\n",
    "            addresses = [address_str]\n",
    "\n",
    "        for addr in addresses:\n",
    "            addr = addr.strip()\n",
    "            if not addr:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                match = email_pattern.search(addr)\n",
    "                if match:\n",
    "                    if match.group(2):  # Format: \"Name <email@example.com>\"\n",
    "                        name = match.group(1).strip().strip('\"')\n",
    "                        email_addr = match.group(2).strip()\n",
    "                    else:  # Format: \"email@example.com\"\n",
    "                        email_addr = match.group(3).strip()\n",
    "                        name = email_addr  # Use email as name if no name is provided\n",
    "\n",
    "                    # Validate email format to a minimum degree\n",
    "                    if '@' in email_addr:\n",
    "                        # Create Entity with EmailAddress\n",
    "                        try:\n",
    "                            email_obj = EmailAddress(email=email_addr)\n",
    "                            entity = Entity(\n",
    "                                name=name,\n",
    "                                email=email_obj,\n",
    "                                is_physical_person=True  # Assuming default\n",
    "                            )\n",
    "                            entities.append(entity)\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error creating Entity for email {email_addr}: {e}\")\n",
    "                else:\n",
    "                    # Try a more forgiving approach if the regex didn't match\n",
    "                    parts = addr.split('@')\n",
    "                    if len(parts) == 2 and '.' in parts[1]:\n",
    "                        # Looks like a valid email\n",
    "                        email_addr = addr.strip()\n",
    "                        try:\n",
    "                            email_obj = EmailAddress(email=email_addr)\n",
    "                            entity = Entity(\n",
    "                                name=email_addr,  # Use email as name\n",
    "                                email=email_obj,\n",
    "                                is_physical_person=True\n",
    "                            )\n",
    "                            entities.append(entity)\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error creating Entity for fallback email {email_addr}: {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error parsing address '{addr}': {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing addresses string '{address_str}': {e}\")\n",
    "\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "250d6017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_str(s):\n",
    "    \"\"\"Decode encoded email header strings\"\"\"\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    try:\n",
    "        decoded_parts = decode_header(s)\n",
    "        return ''.join([\n",
    "            part.decode(encoding or 'utf-8', errors='replace') if isinstance(part, bytes) else part\n",
    "            for part, encoding in decoded_parts\n",
    "        ])\n",
    "    except:\n",
    "        return str(s)\n",
    "\n",
    "def extract_clean_text_from_html(html_content):\n",
    "    \"\"\"\n",
    "    Extract clean, readable text from HTML content.\n",
    "\n",
    "    Args:\n",
    "        html_content (str): HTML content to clean\n",
    "\n",
    "    Returns:\n",
    "        str: Clean text without HTML tags\n",
    "    \"\"\"\n",
    "    if not html_content:\n",
    "        return \"\"\n",
    "\n",
    "    try:\n",
    "        # Remove scripts, styles, and other tags that contain content we don't want\n",
    "        html_content = re.sub(r'<(script|style|head).*?>.*?</\\1>', ' ', html_content, flags=re.DOTALL)\n",
    "\n",
    "        # Replace common block elements with newlines to preserve structure\n",
    "        html_content = re.sub(r'</(p|div|h\\d|tr|li)>', '\\n', html_content)\n",
    "        html_content = re.sub(r'<br[^>]*>', '\\n', html_content)\n",
    "\n",
    "        # Replace table cells with tab separation\n",
    "        html_content = re.sub(r'</td>', '\\t', html_content)\n",
    "\n",
    "        # Remove all HTML tags\n",
    "        text = re.sub(r'<[^>]+>', ' ', html_content)\n",
    "\n",
    "        # Decode HTML entities (&nbsp;, &lt;, etc.)\n",
    "        text = html.unescape(text)\n",
    "\n",
    "        # Handle literal escape sequences that appear in the text\n",
    "        # Replace literal \"\\xad\" with empty string (remove soft hyphens)\n",
    "        text = text.replace('\\\\xad', '')\n",
    "        # Replace literal \"\\xa0\" with a space (non-breaking spaces)\n",
    "        text = text.replace('\\\\xa0', ' ')\n",
    "\n",
    "        # Handle actual Unicode characters too\n",
    "        # Remove soft hyphens (invisible hyphens used for word breaks)\n",
    "        text = text.replace('\\xad', '')\n",
    "        # Replace non-breaking spaces with regular spaces\n",
    "        text = text.replace('\\xa0', ' ')\n",
    "        # Remove other problematic control characters\n",
    "        text = re.sub(r'[\\x00-\\x08\\x0b-\\x0c\\x0e-\\x1f\\x7f]', '', text)\n",
    "\n",
    "        # Clean up other escape sequences that might appear in text\n",
    "        text = text.replace('\\\\\\\\', '\\\\')  # Double backslash to single\n",
    "        text = text.replace(\"\\\\'\", \"'\")    # Escaped single quote\n",
    "        text = text.replace('\\\\\"', '\"')    # Escaped double quote\n",
    "        text = text.replace('\\\\n', '\\n')   # Literal \\n to newline\n",
    "        text = text.replace('\\\\t', '\\t')   # Literal \\t to tab\n",
    "\n",
    "        # Remove remaining literal escape sequences like \\x.. that weren't handled above\n",
    "        text = re.sub(r'\\\\x[0-9a-fA-F]{2}', '', text)\n",
    "\n",
    "        # Clean up whitespace (multiple spaces, tabs, newlines)\n",
    "        text = re.sub(r'[ \\t]+', ' ', text)\n",
    "        text = re.sub(r'\\n{3,}', '\\n\\n', text)\n",
    "\n",
    "        # Final cleanup to remove leading/trailing whitespace\n",
    "        return text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing HTML: {e}\")\n",
    "        return f\"Error processing HTML content: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fb08309",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_email_body(message):\n",
    "    \"\"\"Extract body text from email message, handling HTML correctly\"\"\"\n",
    "    body_text = \"\"\n",
    "    body_html = \"\"\n",
    "\n",
    "    if message.is_multipart():\n",
    "        for part in message.walk():\n",
    "            content_type = part.get_content_type()\n",
    "            content_disposition = str(part.get(\"Content-Disposition\") or \"\")\n",
    "\n",
    "            # Skip attachments\n",
    "            if \"attachment\" in content_disposition:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                payload = part.get_payload(decode=True)\n",
    "                if payload is None:\n",
    "                    continue\n",
    "\n",
    "                charset = part.get_content_charset() or 'utf-8'\n",
    "                decoded_payload = payload.decode(charset, errors='replace')\n",
    "\n",
    "                if content_type == \"text/plain\":\n",
    "                    body_text += decoded_payload\n",
    "                elif content_type == \"text/html\":\n",
    "                    body_html += decoded_payload\n",
    "            except:\n",
    "                continue\n",
    "    else:\n",
    "        # Not multipart - get payload directly\n",
    "        try:\n",
    "            content_type = message.get_content_type()\n",
    "            payload = message.get_payload(decode=True)\n",
    "            if payload:\n",
    "                charset = message.get_content_charset() or 'utf-8'\n",
    "                decoded_payload = payload.decode(charset, errors='replace')\n",
    "\n",
    "                if content_type == \"text/plain\":\n",
    "                    body_text = decoded_payload\n",
    "                elif content_type == \"text/html\":\n",
    "                    body_html = decoded_payload\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Prefer HTML content but fall back to plain text\n",
    "    if body_html:\n",
    "        return {\n",
    "            \"html\": body_html,\n",
    "            \"text\": extract_clean_text_from_html(body_html),\n",
    "            \"has_html\": True\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"html\": \"\",\n",
    "            \"text\": body_text,\n",
    "            \"has_html\": False\n",
    "        }\n",
    "\n",
    "def extract_attachments_info(message):\n",
    "    \"\"\"Extract information about attachments with better error handling\"\"\"\n",
    "    attachments = []\n",
    "\n",
    "    if not message.is_multipart():\n",
    "        return attachments\n",
    "\n",
    "    try:\n",
    "        for part in message.walk():\n",
    "            try:\n",
    "                content_disposition = str(part.get(\"Content-Disposition\") or \"\")\n",
    "\n",
    "                if \"attachment\" in content_disposition:\n",
    "                    try:\n",
    "                        filename = part.get_filename()\n",
    "                        if filename:\n",
    "                            try:\n",
    "                                filename = decode_str(filename)\n",
    "                            except Exception as e:\n",
    "                                print(f\"Error decoding attachment filename: {e}\")\n",
    "                                filename = \"unknown_filename\"\n",
    "                        else:\n",
    "                            filename = \"unnamed_attachment\"\n",
    "\n",
    "                        content_type = part.get_content_type() or 'application/octet-stream'\n",
    "\n",
    "                        # Get content safely\n",
    "                        try:\n",
    "                            content = part.get_payload(decode=True)\n",
    "                            # Ensure content is bytes\n",
    "                            if content is None:\n",
    "                                content = b''\n",
    "                            elif not isinstance(content, bytes):\n",
    "                                content = str(content).encode('utf-8', errors='replace')\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error getting attachment content: {e}\")\n",
    "                            content = b''\n",
    "\n",
    "                        size = len(content)\n",
    "\n",
    "                        attachments.append({\n",
    "                            \"filename\": filename,\n",
    "                            \"content_type\": content_type,\n",
    "                            \"size\": size,\n",
    "                            \"content\": content\n",
    "                        })\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing individual attachment: {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error walking email part: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in attachment extraction: {e}\")\n",
    "\n",
    "    return attachments\n",
    "\n",
    "def extract_recipients(message):\n",
    "    \"\"\"Extract all recipients (To, CC, BCC) as Entity objects with better error handling\"\"\"\n",
    "    to_str = decode_str(message.get('to') or \"\")\n",
    "    cc_str = decode_str(message.get('cc') or \"\")\n",
    "    bcc_str = decode_str(message.get('bcc') or \"\")\n",
    "    reply_to_str = decode_str(message.get('reply-to') or \"\")\n",
    "\n",
    "    # Parse with error handling\n",
    "    try:\n",
    "        to_entities = parse_email_address(to_str)\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing 'to' field: {e}, value: {to_str}\")\n",
    "        to_entities = []\n",
    "\n",
    "    try:\n",
    "        cc_entities = parse_email_address(cc_str)\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing 'cc' field: {e}, value: {cc_str}\")\n",
    "        cc_entities = []\n",
    "\n",
    "    try:\n",
    "        bcc_entities = parse_email_address(bcc_str)\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing 'bcc' field: {e}, value: {bcc_str}\")\n",
    "        bcc_entities = []\n",
    "\n",
    "    reply_to_entity = None\n",
    "    try:\n",
    "        reply_to_entities = parse_email_address(reply_to_str)\n",
    "        if reply_to_entities and len(reply_to_entities) > 0:\n",
    "            reply_to_entity = reply_to_entities[0]\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing 'reply-to' field: {e}, value: {reply_to_str}\")\n",
    "\n",
    "    return {\n",
    "        \"to\": to_entities,\n",
    "        \"cc\": cc_entities,\n",
    "        \"bcc\": bcc_entities,\n",
    "        \"reply_to\": reply_to_entity\n",
    "    }\n",
    "\n",
    "def extract_message_data(message, folder_name):\n",
    "    \"\"\"Extract comprehensive email data to match Pydantic models\"\"\"\n",
    "    # Generate a unique ID\n",
    "    email_id = str(uuid.uuid4())\n",
    "\n",
    "    # Extract basic headers\n",
    "    subject = decode_str(message.get('subject') or \"\")\n",
    "    from_str = decode_str(message.get('from') or \"\")\n",
    "    date_str = message.get('date')\n",
    "    message_id = decode_str(message.get('message-id') or \"\")\n",
    "    in_reply_to = decode_str(message.get('in-reply-to') or \"\")\n",
    "    references = decode_str(message.get('references') or \"\")\n",
    "\n",
    "    # Parse date\n",
    "    try:\n",
    "        timestamp = email.utils.parsedate_to_datetime(date_str)\n",
    "    except:\n",
    "        timestamp = datetime.datetime.now()  # Fallback to current time\n",
    "\n",
    "    # Get sender entity\n",
    "    try:\n",
    "        sender_entities = parse_email_address(from_str)\n",
    "        if sender_entities and len(sender_entities) > 0:\n",
    "            sender_entity = sender_entities[0]\n",
    "        else:\n",
    "            # Create a fallback entity if parsing failed\n",
    "            sender_entity = Entity(\n",
    "                name=\"Unknown\",\n",
    "                email=EmailAddress(email=\"unknown@example.com\"),\n",
    "                is_physical_person=True\n",
    "            )\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing sender: {e}, from_str: {from_str}\")\n",
    "        sender_entity = Entity(\n",
    "            name=\"Unknown\",\n",
    "            email=EmailAddress(email=\"unknown@example.com\"),\n",
    "            is_physical_person=True\n",
    "        )\n",
    "\n",
    "    # Get recipients\n",
    "    try:\n",
    "        recipients = extract_recipients(message)\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting recipients: {e}\")\n",
    "        # Create empty recipients if extraction fails\n",
    "        recipients = {\n",
    "            \"to\": [],\n",
    "            \"cc\": [],\n",
    "            \"bcc\": [],\n",
    "            \"reply_to\": None\n",
    "        }\n",
    "\n",
    "    # Get body content\n",
    "    try:\n",
    "        body_content = get_email_body(message)\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting body: {e}\")\n",
    "        body_content = {\n",
    "            \"text\": \"\",\n",
    "            \"html\": \"\",\n",
    "            \"has_html\": False\n",
    "        }\n",
    "\n",
    "    # Get attachment info with careful error handling\n",
    "    attachments = []\n",
    "    try:\n",
    "        attachments_data = extract_attachments_info(message)\n",
    "        for att in attachments_data:\n",
    "            if \"filename\" in att and att[\"filename\"]:\n",
    "                try:\n",
    "                    # Create a safe version of the content\n",
    "                    content = att.get(\"content\", b'')\n",
    "                    if not isinstance(content, bytes):\n",
    "                        content = b''\n",
    "\n",
    "                    attachment = Attachment(\n",
    "                        filename=att[\"filename\"],\n",
    "                        content=content\n",
    "                    )\n",
    "\n",
    "                    # Add optional metadata safely\n",
    "                    attachment.content_type = att.get('content_type', 'application/octet-stream')\n",
    "                    attachment.size = att.get('size', len(content))\n",
    "\n",
    "                    attachments.append(attachment)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error creating attachment object: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting attachments: {e}\")\n",
    "\n",
    "    # Check if this is potentially a mailing list\n",
    "    list_id = decode_str(message.get('list-id') or \"\")\n",
    "    list_unsubscribe = decode_str(message.get('list-unsubscribe') or \"\")\n",
    "    is_mailing_list = bool(list_id or list_unsubscribe)\n",
    "\n",
    "    # Create a mailing list object if applicable\n",
    "    mailing_list = None\n",
    "    if is_mailing_list and list_id:\n",
    "        try:\n",
    "            # Extract name from list-id which often looks like \"List Name <listname.example.com>\"\n",
    "            # list_name_match = re.search(r'<([^>]+)>|([^,\\s]+)', list_id)\n",
    "            # list_name = list_name_match.group(1) if list_name_match else \"Unknown List\"\n",
    "            list_name_match = re.search(r'<([^>]+)>|([^,\\s]+)', list_id)\n",
    "\n",
    "            if list_name_match:\n",
    "                # Check both capture groups\n",
    "                list_name = list_name_match.group(1) or list_name_match.group(2) or \"Unknown List\"\n",
    "            else:\n",
    "                list_name = \"Unknown List\"\n",
    "\n",
    "            # Try to find a list email address\n",
    "            list_email = \"list@example.com\"  # Default\n",
    "            list_email_match = re.search(r'([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+)', list_unsubscribe)\n",
    "            if list_email_match:\n",
    "                list_email = list_email_match.group(1)\n",
    "\n",
    "            mailing_list = MailingList(\n",
    "                id=str(uuid.uuid4()),\n",
    "                name=list_name,\n",
    "                description=f\"Mailing list extracted from {list_id}\",\n",
    "                email_address=EmailAddress(email=list_email)\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating mailing list: {e}\")\n",
    "\n",
    "    # Create a SenderEmail object\n",
    "    sender_email_id = str(uuid.uuid4())\n",
    "    sender_email = SenderEmail(\n",
    "        id=sender_email_id,\n",
    "        sender=sender_entity,\n",
    "        body=body_content[\"text\"],\n",
    "        timestamp=timestamp\n",
    "    )\n",
    "\n",
    "    # Create a ReceiverEmail object - safely handle the recipients\n",
    "    receiver_email = ReceiverEmail(\n",
    "        id=email_id,\n",
    "        sender_email=sender_email,\n",
    "        sender=sender_entity,\n",
    "        to=recipients.get(\"to\") if recipients.get(\"to\") else None,\n",
    "        reply_to=recipients.get(\"reply_to\"),\n",
    "        cc=recipients.get(\"cc\") if recipients.get(\"cc\") else None,\n",
    "        bcc=recipients.get(\"bcc\") if recipients.get(\"bcc\") else None,\n",
    "        timestamp=timestamp,\n",
    "        subject=subject,\n",
    "        body=body_content[\"text\"],\n",
    "        attachments=attachments if attachments else None,\n",
    "        is_deleted=False,\n",
    "        folder=folder_name,\n",
    "        is_spam=False,\n",
    "        mailing_list=mailing_list,\n",
    "        importance_score=0,  # Default value\n",
    "        mother_email=None,  # Will be linked later based on in_reply_to\n",
    "        children_emails=None\n",
    "    )\n",
    "\n",
    "    # Create a data dictionary for our normalized database tables\n",
    "    email_data = {\n",
    "        'id': email_id,\n",
    "        'sender_email_id': sender_email.id,\n",
    "        'sender_id': None,  # Will be filled in by the processing function\n",
    "        'reply_to_id': None,  # Will be filled in by the processing function\n",
    "        'timestamp': timestamp,\n",
    "        'subject': subject,\n",
    "        'body': body_content[\"text\"],\n",
    "        'body_html': body_content[\"html\"] if body_content[\"has_html\"] else None,\n",
    "        'has_html': body_content[\"has_html\"],\n",
    "        'is_deleted': False,\n",
    "        'folder': folder_name,\n",
    "        'is_spam': False,\n",
    "        'mailing_list_id': mailing_list.id if mailing_list else None,\n",
    "        'importance_score': 0,\n",
    "        'mother_email_id': None,  # Will be updated later based on in_reply_to\n",
    "        'message_id': message_id,\n",
    "        'references': references,\n",
    "        'in_reply_to': in_reply_to\n",
    "    }\n",
    "\n",
    "    return email_data, receiver_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d058dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import email\n",
    "from email import policy\n",
    "from typing import List, Dict, Any, Optional, Union\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "def collect_email_data(directory: Union[str, Path],\n",
    "                       include_html: bool = True,\n",
    "                       include_attachments: bool = True) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Recursively process all .eml files in the directory and its subdirectories\n",
    "    and return a list of email data.\n",
    "\n",
    "    Args:\n",
    "        directory: Root directory to search for .eml files\n",
    "        include_html: Whether to include HTML content in the email data\n",
    "        include_attachments: Whether to include attachment information\n",
    "\n",
    "    Returns:\n",
    "        List of dictionaries containing extracted email data\n",
    "    \"\"\"\n",
    "    all_emails = []\n",
    "    directory = Path(directory)  # Convert to Path object if it's a string\n",
    "\n",
    "    # Find all .eml files recursively\n",
    "    eml_files = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.eml'):\n",
    "                eml_files.append(Path(root) / file)\n",
    "\n",
    "    print(f\"Found {len(eml_files)} .eml files\")\n",
    "\n",
    "    # Process each file\n",
    "    for eml_path in tqdm(eml_files, desc=\"Processing emails\"):\n",
    "        # Determine folder structure relative to the root directory\n",
    "        rel_path = eml_path.relative_to(directory)\n",
    "        folder_name = str(rel_path.parent) if rel_path.parent != Path('.') else 'root'\n",
    "\n",
    "        try:\n",
    "            # Parse the email file\n",
    "            with open(eml_path, 'rb') as f:\n",
    "                message = email.message_from_binary_file(f, policy=policy.default)\n",
    "\n",
    "            email_data = extract_message_data(message, folder_name)\n",
    "\n",
    "            # Add the file path for reference\n",
    "            email_data['file_path'] = str(eml_path)\n",
    "\n",
    "            # Optionally exclude HTML content to reduce data size\n",
    "            if not include_html:\n",
    "                email_data.pop('body_html', None)\n",
    "\n",
    "            # Optionally simplify attachment info to reduce data size\n",
    "            if not include_attachments:\n",
    "                email_data['attachment_count'] = len(email_data.get('attachments', []))\n",
    "                email_data.pop('attachments', None)\n",
    "\n",
    "            all_emails.append(email_data)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {eml_path}: {e}\")\n",
    "\n",
    "    return all_emails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0624feb",
   "metadata": {},
   "source": [
    "### Setup Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611bd35a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f29dfb77",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486f929e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f31dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import json\n",
    "import email\n",
    "from email import policy\n",
    "from typing import Dict, Optional, Union, Any\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_eml_to_duckdb(directory: Union[str, Path],\n",
    "                          conn: 'duckdb.DuckDBPyConnection',\n",
    "                          batch_size: int = 100,\n",
    "                          entity_cache: Optional[Dict[str, str]] = None) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Recursively process all .eml files in a directory and its subdirectories directly to DuckDB in batches\n",
    "\n",
    "    Args:\n",
    "        directory: Root directory to search for .eml files\n",
    "        conn: DuckDB connection\n",
    "        batch_size: Number of records to process before committing to the database\n",
    "        entity_cache: Cache to store entities we've already seen\n",
    "\n",
    "    Returns:\n",
    "        Updated entity cache after processing\n",
    "    \"\"\"\n",
    "    if entity_cache is None:\n",
    "        entity_cache = {}  # Cache to store entities we've already seen\n",
    "\n",
    "    directory = Path(directory)  # Convert to Path object if it's a string\n",
    "\n",
    "    # Find all .eml files recursively\n",
    "    eml_files = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.eml'):\n",
    "                eml_files.append(Path(root) / file)\n",
    "\n",
    "    print(f\"Found {len(eml_files)} .eml files to process\")\n",
    "\n",
    "    # Process in batches for each table\n",
    "    entity_batch = []\n",
    "    entity_alias_emails_batch = []\n",
    "    mailing_list_batch = []\n",
    "    sender_email_batch = []\n",
    "    receiver_email_batch = []\n",
    "    to_recipients_batch = []\n",
    "    cc_recipients_batch = []\n",
    "    bcc_recipients_batch = []\n",
    "    attachments_batch = []\n",
    "\n",
    "    # Process each .eml file\n",
    "    for i, eml_path in enumerate(tqdm(eml_files, desc=\"Processing emails\")):\n",
    "        # Determine folder structure relative to the root directory\n",
    "        rel_path = eml_path.relative_to(directory)\n",
    "        folder_name = str(rel_path.parent) if rel_path.parent != Path('.') else 'root'\n",
    "\n",
    "        try:\n",
    "            # Parse the email file\n",
    "            with open(eml_path, 'rb') as f:\n",
    "                message = email.message_from_binary_file(f, policy=policy.default)\n",
    "\n",
    "            email_data, receiver_email = extract_message_data(message, folder_name)\n",
    "\n",
    "            # Process sender entity\n",
    "            sender = receiver_email.sender\n",
    "            if sender.email.email not in entity_cache:\n",
    "                entity_id = str(uuid.uuid4())\n",
    "                entity_cache[sender.email.email] = entity_id\n",
    "\n",
    "                # Add to entities batch\n",
    "                entity_batch.append({\n",
    "                    'id': entity_id,\n",
    "                    'name': sender.name,\n",
    "                    'email': sender.email.email,\n",
    "                    'alias_names': json.dumps(sender.alias_names) if sender.alias_names else None,\n",
    "                    'is_physical_person': sender.is_physical_person\n",
    "                })\n",
    "\n",
    "                # Process alias emails if any\n",
    "                if sender.alias_emails:\n",
    "                    for alias_email in sender.alias_emails:\n",
    "                        entity_alias_emails_batch.append({\n",
    "                            'id': str(uuid.uuid4()),\n",
    "                            'entity_id': entity_id,\n",
    "                            'email': alias_email.email\n",
    "                        })\n",
    "            else:\n",
    "                # Get cached entity ID\n",
    "                entity_id = entity_cache[sender.email.email]\n",
    "\n",
    "            # Process sender email\n",
    "            sender_email = receiver_email.sender_email\n",
    "            sender_email_batch.append({\n",
    "                'id': sender_email.id,\n",
    "                'sender_id': entity_id,  # Use cached or new entity ID\n",
    "                'body': sender_email.body,\n",
    "                'timestamp': sender_email.timestamp\n",
    "            })\n",
    "\n",
    "            # Process receiver email\n",
    "            reply_to_id = None\n",
    "            if receiver_email.reply_to:\n",
    "                reply_to_email = receiver_email.reply_to.email.email\n",
    "                if reply_to_email not in entity_cache:\n",
    "                    reply_to_id = str(uuid.uuid4())\n",
    "                    entity_cache[reply_to_email] = reply_to_id\n",
    "\n",
    "                    entity_batch.append({\n",
    "                        'id': reply_to_id,\n",
    "                        'name': receiver_email.reply_to.name,\n",
    "                        'email': reply_to_email,\n",
    "                        'alias_names': None,\n",
    "                        'is_physical_person': True\n",
    "                    })\n",
    "                else:\n",
    "                    reply_to_id = entity_cache[reply_to_email]\n",
    "\n",
    "            # Add mailing list if present\n",
    "            mailing_list_id = None\n",
    "            if receiver_email.mailing_list:\n",
    "                mailing_list_id = receiver_email.mailing_list.id\n",
    "                mailing_list_batch.append({\n",
    "                    'id': mailing_list_id,\n",
    "                    'name': receiver_email.mailing_list.name,\n",
    "                    'description': receiver_email.mailing_list.description,\n",
    "                    'email_address': receiver_email.mailing_list.email_address.email\n",
    "                })\n",
    "\n",
    "            # Add receiver email\n",
    "            receiver_email_batch.append({\n",
    "                'id': receiver_email.id,\n",
    "                'sender_email_id': sender_email.id,\n",
    "                'sender_id': entity_id,\n",
    "                'reply_to_id': reply_to_id,\n",
    "                'timestamp': receiver_email.timestamp,\n",
    "                'subject': receiver_email.subject,\n",
    "                'body': receiver_email.body,\n",
    "                'body_html': email_data.get('body_html'),\n",
    "                'has_html': email_data.get('has_html', False),\n",
    "                'is_deleted': receiver_email.is_deleted,\n",
    "                'folder': folder_name,  # Using the relative folder path as folder name\n",
    "                'is_spam': receiver_email.is_spam,\n",
    "                'mailing_list_id': mailing_list_id,\n",
    "                'importance_score': receiver_email.importance_score,\n",
    "                'mother_email_id': None,  # Will be updated later\n",
    "                'message_id': email_data.get('message_id'),\n",
    "                'references': email_data.get('references'),\n",
    "                'in_reply_to': email_data.get('in_reply_to')\n",
    "            })\n",
    "\n",
    "            # Process recipients (to, cc, bcc)\n",
    "            if receiver_email.to:\n",
    "                for entity in receiver_email.to:\n",
    "                    if entity.email.email not in entity_cache:\n",
    "                        to_entity_id = str(uuid.uuid4())\n",
    "                        entity_cache[entity.email.email] = to_entity_id\n",
    "\n",
    "                        entity_batch.append({\n",
    "                            'id': to_entity_id,\n",
    "                            'name': entity.name,\n",
    "                            'email': entity.email.email,\n",
    "                            'alias_names': json.dumps(entity.alias_names) if entity.alias_names else None,\n",
    "                            'is_physical_person': entity.is_physical_person\n",
    "                        })\n",
    "\n",
    "                        # Process alias emails\n",
    "                        if entity.alias_emails:\n",
    "                            for alias_email in entity.alias_emails:\n",
    "                                entity_alias_emails_batch.append({\n",
    "                                    'id': str(uuid.uuid4()),\n",
    "                                    'entity_id': to_entity_id,\n",
    "                                    'email': alias_email.email\n",
    "                                })\n",
    "                    else:\n",
    "                        to_entity_id = entity_cache[entity.email.email]\n",
    "\n",
    "                    # Add to recipients relationship\n",
    "                    to_recipients_batch.append({\n",
    "                        'email_id': receiver_email.id,\n",
    "                        'entity_id': to_entity_id\n",
    "                    })\n",
    "\n",
    "            # Process CC recipients\n",
    "            if receiver_email.cc:\n",
    "                for entity in receiver_email.cc:\n",
    "                    if entity.email.email not in entity_cache:\n",
    "                        cc_entity_id = str(uuid.uuid4())\n",
    "                        entity_cache[entity.email.email] = cc_entity_id\n",
    "\n",
    "                        entity_batch.append({\n",
    "                            'id': cc_entity_id,\n",
    "                            'name': entity.name,\n",
    "                            'email': entity.email.email,\n",
    "                            'alias_names': json.dumps(entity.alias_names) if entity.alias_names else None,\n",
    "                            'is_physical_person': entity.is_physical_person\n",
    "                        })\n",
    "                    else:\n",
    "                        cc_entity_id = entity_cache[entity.email.email]\n",
    "\n",
    "                    # Add cc recipients relationship\n",
    "                    cc_recipients_batch.append({\n",
    "                        'email_id': receiver_email.id,\n",
    "                        'entity_id': cc_entity_id\n",
    "                    })\n",
    "\n",
    "            # Process BCC recipients\n",
    "            if receiver_email.bcc:\n",
    "                for entity in receiver_email.bcc:\n",
    "                    if entity.email.email not in entity_cache:\n",
    "                        bcc_entity_id = str(uuid.uuid4())\n",
    "                        entity_cache[entity.email.email] = bcc_entity_id\n",
    "\n",
    "                        entity_batch.append({\n",
    "                            'id': bcc_entity_id,\n",
    "                            'name': entity.name,\n",
    "                            'email': entity.email.email,\n",
    "                            'alias_names': json.dumps(entity.alias_names) if entity.alias_names else None,\n",
    "                            'is_physical_person': entity.is_physical_person\n",
    "                        })\n",
    "                    else:\n",
    "                        bcc_entity_id = entity_cache[entity.email.email]\n",
    "\n",
    "                    # Add bcc recipients relationship\n",
    "                    bcc_recipients_batch.append({\n",
    "                        'email_id': receiver_email.id,\n",
    "                        'entity_id': bcc_entity_id\n",
    "                    })\n",
    "\n",
    "            # Process attachments\n",
    "            if receiver_email.attachments:\n",
    "                for attachment in receiver_email.attachments:\n",
    "                    content_type = getattr(attachment, 'content_type', 'application/octet-stream')\n",
    "                    size = getattr(attachment, 'size', len(attachment.content) if attachment.content else 0)\n",
    "\n",
    "                    attachments_batch.append({\n",
    "                        'id': str(uuid.uuid4()),\n",
    "                        'email_id': receiver_email.id,\n",
    "                        'filename': attachment.filename,\n",
    "                        'content': attachment.content,\n",
    "                        'content_type': content_type,\n",
    "                        'size': size\n",
    "                    })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing email {eml_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Process batch when it reaches the batch size or on the last file\n",
    "        if len(receiver_email_batch) >= batch_size or i == len(eml_files) - 1:\n",
    "            try:\n",
    "                # Insert entities\n",
    "                if entity_batch:\n",
    "                    entities_df = pd.DataFrame(entity_batch)\n",
    "                    conn.execute(\"\"\"\n",
    "                    INSERT OR IGNORE INTO entities\n",
    "                    SELECT * FROM entities_df\n",
    "                    \"\"\")\n",
    "                    entity_batch = []\n",
    "\n",
    "                # Insert entity alias emails\n",
    "                if entity_alias_emails_batch:\n",
    "                    alias_emails_df = pd.DataFrame(entity_alias_emails_batch)\n",
    "                    conn.execute(\"\"\"\n",
    "                    INSERT OR IGNORE INTO entity_alias_emails\n",
    "                    SELECT * FROM alias_emails_df\n",
    "                    \"\"\")\n",
    "                    entity_alias_emails_batch = []\n",
    "\n",
    "                # Insert mailing lists\n",
    "                if mailing_list_batch:\n",
    "                    mailing_lists_df = pd.DataFrame(mailing_list_batch)\n",
    "                    conn.execute(\"\"\"\n",
    "                    INSERT OR IGNORE INTO mailing_lists\n",
    "                    SELECT * FROM mailing_lists_df\n",
    "                    \"\"\")\n",
    "                    mailing_list_batch = []\n",
    "\n",
    "                # Insert sender emails\n",
    "                if sender_email_batch:\n",
    "                    sender_emails_df = pd.DataFrame(sender_email_batch)\n",
    "                    conn.execute(\"\"\"\n",
    "                    INSERT OR IGNORE INTO sender_emails\n",
    "                    SELECT * FROM sender_emails_df\n",
    "                    \"\"\")\n",
    "                    sender_email_batch = []\n",
    "\n",
    "                # Insert receiver emails\n",
    "                if receiver_email_batch:\n",
    "                    receiver_emails_df = pd.DataFrame(receiver_email_batch)\n",
    "                    conn.execute(\"\"\"\n",
    "                    INSERT OR IGNORE INTO receiver_emails\n",
    "                    SELECT * FROM receiver_emails_df\n",
    "                    \"\"\")\n",
    "                    receiver_email_batch = []\n",
    "\n",
    "                # Insert recipient relationships\n",
    "                if to_recipients_batch:\n",
    "                    to_recipients_df = pd.DataFrame(to_recipients_batch)\n",
    "                    conn.execute(\"\"\"\n",
    "                    INSERT OR IGNORE INTO email_recipients_to\n",
    "                    SELECT * FROM to_recipients_df\n",
    "                    \"\"\")\n",
    "                    to_recipients_batch = []\n",
    "\n",
    "                if cc_recipients_batch:\n",
    "                    cc_recipients_df = pd.DataFrame(cc_recipients_batch)\n",
    "                    conn.execute(\"\"\"\n",
    "                    INSERT OR IGNORE INTO email_recipients_cc\n",
    "                    SELECT * FROM cc_recipients_df\n",
    "                    \"\"\")\n",
    "                    cc_recipients_batch = []\n",
    "\n",
    "                if bcc_recipients_batch:\n",
    "                    bcc_recipients_df = pd.DataFrame(bcc_recipients_batch)\n",
    "                    conn.execute(\"\"\"\n",
    "                    INSERT OR IGNORE INTO email_recipients_bcc\n",
    "                    SELECT * FROM bcc_recipients_df\n",
    "                    \"\"\")\n",
    "                    bcc_recipients_batch = []\n",
    "\n",
    "                # Insert attachments\n",
    "                if attachments_batch:\n",
    "                    attachments_df = pd.DataFrame(attachments_batch)\n",
    "                    conn.execute(\"\"\"\n",
    "                    INSERT OR IGNORE INTO attachments\n",
    "                    SELECT * FROM attachments_df\n",
    "                    \"\"\")\n",
    "                    attachments_batch = []\n",
    "\n",
    "                # Commit to save progress\n",
    "                conn.commit()\n",
    "            except Exception as e:\n",
    "                print(f\"Error inserting batch into database: {e}\")\n",
    "                # Continue processing even if one batch fails\n",
    "                entity_batch = []\n",
    "                entity_alias_emails_batch = []\n",
    "                mailing_list_batch = []\n",
    "                sender_email_batch = []\n",
    "                receiver_email_batch = []\n",
    "                to_recipients_batch = []\n",
    "                cc_recipients_batch = []\n",
    "                bcc_recipients_batch = []\n",
    "                attachments_batch = []\n",
    "\n",
    "    print(f\"Completed processing {len(eml_files)} .eml files\")\n",
    "\n",
    "    return entity_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26676d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def process_eml_files(directory: Union[str, Path],\n",
    "                     output_path: Optional[str] = None) -> None:\n",
    "    \"\"\"\n",
    "    Recursively process .eml files from a directory and its subdirectories and save to DuckDB format\n",
    "    with normalized tables\n",
    "\n",
    "    Args:\n",
    "        directory: Directory containing .eml files (may be nested in subdirectories)\n",
    "        output_path: Output file path (default: emails.duckdb)\n",
    "    \"\"\"\n",
    "    # Set default output path if not provided\n",
    "    if output_path is None:\n",
    "        output_path = 'emails.duckdb'\n",
    "    elif not output_path.endswith('.duckdb'):\n",
    "        output_path = f\"{output_path}.duckdb\"\n",
    "\n",
    "    # Setup database\n",
    "    conn = setup_database(output_path)\n",
    "\n",
    "    # Convert directory to Path if it's a string\n",
    "    directory = Path(directory)\n",
    "\n",
    "    # Entity cache to avoid duplicates across files\n",
    "    entity_cache = {}\n",
    "\n",
    "    try:\n",
    "        # Process all .eml files in the directory and subdirectories\n",
    "        print(f\"Processing .eml files in {directory} and subdirectories...\")\n",
    "        entity_cache = process_eml_to_duckdb(directory, conn, entity_cache=entity_cache)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing directory {directory}: {e}\")\n",
    "\n",
    "    try:\n",
    "        # Create relationships between emails (mother/child relationships)\n",
    "        print(\"Creating email thread relationships...\")\n",
    "        conn.execute(\"\"\"\n",
    "        UPDATE receiver_emails\n",
    "        SET mother_email_id = (\n",
    "            SELECT r2.id\n",
    "            FROM receiver_emails r2\n",
    "            WHERE r2.message_id = receiver_emails.in_reply_to\n",
    "            LIMIT 1\n",
    "        )\n",
    "        WHERE in_reply_to IS NOT NULL\n",
    "        \"\"\")\n",
    "\n",
    "        # Populate the children relationships table\n",
    "        print(\"Populating child email relationships...\")\n",
    "        conn.execute(\"\"\"\n",
    "        INSERT INTO email_children (parent_id, child_id)\n",
    "        SELECT mother_email_id, id\n",
    "        FROM receiver_emails\n",
    "        WHERE mother_email_id IS NOT NULL\n",
    "        AND mother_email_id IN (SELECT id FROM receiver_emails)\n",
    "        AND id != mother_email_id  -- Prevent self-references\n",
    "        \"\"\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Error in relationship creation: {e}\")\n",
    "        print(\"Continuing with database optimization...\")\n",
    "\n",
    "    # Final optimization and cleanup\n",
    "    print(\"Optimizing database...\")\n",
    "    conn.execute(\"PRAGMA optimize_database\")\n",
    "    conn.close()\n",
    "\n",
    "    print(f\"DuckDB database saved to {output_path}\")\n",
    "    print(\"\"\"\n",
    "Database structure:\n",
    "- entities: Stores all senders and recipients\n",
    "- entity_alias_emails: Stores alias emails for entities\n",
    "- sender_emails: Stores email data from senders\n",
    "- receiver_emails: Stores received email data\n",
    "- email_recipients_to/cc/bcc: Links emails to recipient entities\n",
    "- attachments: Stores email attachments\n",
    "- email_children: Stores parent-child relationships between emails\n",
    "- mailing_lists: Stores mailing list information\n",
    "- organizations: Stores organization information\n",
    "- positions: Stores position information\n",
    "- entity_positions: Links entities to positions\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0fc76d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0d77c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb_conn = setup_database(db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3d3e1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup_database(db_path)\n",
    "# duckdb_conn = duckdb.connect(db_path)\n",
    "# process_mbox_to_duckdb(mbox_single_file_path, duckdb_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef48698a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing .eml files in data/processed/real_test_sample and subdirectories...\n",
      "Found 10 .eml files to process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing emails: 100%|| 10/10 [00:00<00:00, 65.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing email data/processed/real_test_sample/Archive/1.eml: name 'extract_message_data' is not defined\n",
      "Error processing email data/processed/real_test_sample/Archive/10.eml: name 'extract_message_data' is not defined\n",
      "Error processing email data/processed/real_test_sample/Archive/2.eml: name 'extract_message_data' is not defined\n",
      "Error processing email data/processed/real_test_sample/Archive/3.eml: name 'extract_message_data' is not defined\n",
      "Error processing email data/processed/real_test_sample/Archive/4.eml: name 'extract_message_data' is not defined\n",
      "Error processing email data/processed/real_test_sample/Archive/5.eml: name 'extract_message_data' is not defined\n",
      "Error processing email data/processed/real_test_sample/Archive/6.eml: name 'extract_message_data' is not defined\n",
      "Error processing email data/processed/real_test_sample/Archive/7.eml: name 'extract_message_data' is not defined\n",
      "Error processing email data/processed/real_test_sample/Archive/8.eml: name 'extract_message_data' is not defined\n",
      "Error processing email data/processed/real_test_sample/Archive/9.eml: name 'extract_message_data' is not defined\n",
      "Completed processing 10 .eml files\n",
      "Creating email thread relationships...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Error in relationship creation: Constraint Error: Violates foreign key constraint because key \"email_id: fca325ff-216c-48e1-a3ed-e5c5af91ae38\" is still referenced by a foreign key in a different table. If this is an unexpected constraint violation, please refer to our foreign key limitations in the documentation\n",
      "Continuing with database optimization...\n",
      "Optimizing database...\n"
     ]
    },
    {
     "ename": "CatalogException",
     "evalue": "Catalog Error: Pragma Function with name optimize_database does not exist!\nDid you mean \"import_database\"?",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCatalogException\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mprocess_eml_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTEST_SAMPLE_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# mbox_path\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 63\u001b[39m, in \u001b[36mprocess_eml_files\u001b[39m\u001b[34m(directory, output_path)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# Final optimization and cleanup\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mOptimizing database...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPRAGMA optimize_database\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m conn.close()\n\u001b[32m     66\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDuckDB database saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mCatalogException\u001b[39m: Catalog Error: Pragma Function with name optimize_database does not exist!\nDid you mean \"import_database\"?"
     ]
    }
   ],
   "source": [
    "process_eml_files(TEST_SAMPLE_PATH, db_path)\n",
    "# mbox_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81dcbb51",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'EmailAnalyzer' from 'src.data.analysis' (/mnt/c/Users/julie/Lab_IA_Project/olkoa/src/data/analysis.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01manalysis\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EmailAnalyzer\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'EmailAnalyzer' from 'src.data.analysis' (/mnt/c/Users/julie/Lab_IA_Project/olkoa/src/data/analysis.py)"
     ]
    }
   ],
   "source": [
    "from src.data.analysis import EmailAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06352d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer =EmailAnalyzer(db_path)\n",
    "analyzer.get_email_summary()\n",
    "\n",
    "df_db_cleaned = analyzer.export_to_dataframe()\n",
    "df_db_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148a45dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All columns in database:\n",
      "('main', 'attachments', 'id', 'VARCHAR')\n",
      "('main', 'attachments', 'email_id', 'VARCHAR')\n",
      "('main', 'attachments', 'filename', 'VARCHAR')\n",
      "('main', 'attachments', 'content', 'BLOB')\n",
      "('main', 'attachments', 'content_type', 'VARCHAR')\n",
      "('main', 'attachments', 'size', 'INTEGER')\n",
      "('main', 'email_children', 'parent_id', 'VARCHAR')\n",
      "('main', 'email_children', 'child_id', 'VARCHAR')\n",
      "('main', 'email_recipients_bcc', 'email_id', 'VARCHAR')\n",
      "('main', 'email_recipients_bcc', 'entity_id', 'VARCHAR')\n",
      "('main', 'email_recipients_cc', 'email_id', 'VARCHAR')\n",
      "('main', 'email_recipients_cc', 'entity_id', 'VARCHAR')\n",
      "('main', 'email_recipients_to', 'email_id', 'VARCHAR')\n",
      "('main', 'email_recipients_to', 'entity_id', 'VARCHAR')\n",
      "('main', 'entities', 'id', 'VARCHAR')\n",
      "('main', 'entities', 'name', 'VARCHAR')\n",
      "('main', 'entities', 'email', 'VARCHAR')\n",
      "('main', 'entities', 'alias_names', 'JSON')\n",
      "('main', 'entities', 'is_physical_person', 'BOOLEAN')\n",
      "('main', 'entity_alias_emails', 'id', 'VARCHAR')\n",
      "('main', 'entity_alias_emails', 'entity_id', 'VARCHAR')\n",
      "('main', 'entity_alias_emails', 'email', 'VARCHAR')\n",
      "('main', 'entity_positions', 'entity_id', 'VARCHAR')\n",
      "('main', 'entity_positions', 'position_id', 'VARCHAR')\n",
      "('main', 'mailing_lists', 'id', 'VARCHAR')\n",
      "('main', 'mailing_lists', 'name', 'VARCHAR')\n",
      "('main', 'mailing_lists', 'description', 'VARCHAR')\n",
      "('main', 'mailing_lists', 'email_address', 'VARCHAR')\n",
      "('main', 'organizations', 'id', 'VARCHAR')\n",
      "('main', 'organizations', 'name', 'VARCHAR')\n",
      "('main', 'organizations', 'description', 'VARCHAR')\n",
      "('main', 'organizations', 'email_address', 'VARCHAR')\n",
      "('main', 'positions', 'id', 'VARCHAR')\n",
      "('main', 'positions', 'name', 'VARCHAR')\n",
      "('main', 'positions', 'start_date', 'TIMESTAMP')\n",
      "('main', 'positions', 'end_date', 'TIMESTAMP')\n",
      "('main', 'positions', 'description', 'VARCHAR')\n",
      "('main', 'positions', 'organization_id', 'VARCHAR')\n",
      "('main', 'receiver_emails', 'id', 'VARCHAR')\n",
      "('main', 'receiver_emails', 'sender_email_id', 'VARCHAR')\n",
      "('main', 'receiver_emails', 'sender_id', 'VARCHAR')\n",
      "('main', 'receiver_emails', 'reply_to_id', 'VARCHAR')\n",
      "('main', 'receiver_emails', 'timestamp', 'TIMESTAMP')\n",
      "('main', 'receiver_emails', 'subject', 'VARCHAR')\n",
      "('main', 'receiver_emails', 'body', 'VARCHAR')\n",
      "('main', 'receiver_emails', 'body_html', 'VARCHAR')\n",
      "('main', 'receiver_emails', 'has_html', 'BOOLEAN')\n",
      "('main', 'receiver_emails', 'is_deleted', 'BOOLEAN')\n",
      "('main', 'receiver_emails', 'folder', 'VARCHAR')\n",
      "('main', 'receiver_emails', 'is_spam', 'BOOLEAN')\n",
      "('main', 'receiver_emails', 'mailing_list_id', 'VARCHAR')\n",
      "('main', 'receiver_emails', 'importance_score', 'INTEGER')\n",
      "('main', 'receiver_emails', 'mother_email_id', 'VARCHAR')\n",
      "('main', 'receiver_emails', 'message_id', 'VARCHAR')\n",
      "('main', 'receiver_emails', 'references', 'VARCHAR')\n",
      "('main', 'receiver_emails', 'in_reply_to', 'VARCHAR')\n",
      "('main', 'sender_emails', 'id', 'VARCHAR')\n",
      "('main', 'sender_emails', 'sender_id', 'VARCHAR')\n",
      "('main', 'sender_emails', 'body', 'VARCHAR')\n",
      "('main', 'sender_emails', 'timestamp', 'TIMESTAMP')\n"
     ]
    }
   ],
   "source": [
    "# Method 1: List all tables\n",
    "# tables = duckdb_conn.execute(\"SELECT * FROM information_schema.tables\").fetchall()\n",
    "# print(\"Tables in database:\")\n",
    "# for table in tables:\n",
    "#     print(table)\n",
    "\n",
    "# Method 2: Get all tables and their columns\n",
    "all_columns = duckdb_conn.execute(\"\"\"\n",
    "    SELECT\n",
    "        table_schema,\n",
    "        table_name,\n",
    "        column_name,\n",
    "        data_type\n",
    "    FROM information_schema.columns\n",
    "    ORDER BY table_schema, table_name, ordinal_position\n",
    "\"\"\").fetchall()\n",
    "print(\"\\nAll columns in database:\")\n",
    "for column in all_columns:\n",
    "    print(column)\n",
    "\n",
    "\n",
    "# duckdb_conn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "olkoa_v3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
