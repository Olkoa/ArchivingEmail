{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8efcaaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragatouille import RAGPretrainedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dc8e051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"COLBERT_LOAD_TORCH_EXTENSION_VERBOSE\"] = \"True\"\n",
    "# Then import and load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fad925df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu124\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3b4eb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(pretrained_model_name_or_path: Union[str, pathlib.Path], n_gpu: int = -1, verbose: int = 1, index_root: Optional[str] = None)\n"
     ]
    }
   ],
   "source": [
    "# Check the available parameters\n",
    "import inspect\n",
    "from ragatouille import RAGPretrainedModel\n",
    "print(inspect.signature(RAGPretrainedModel.from_pretrained))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a920e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 21, 11:29:11] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/julienrm/.cache/torch_extensions/py312_cu124 as PyTorch extensions root...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m rag_model = \u001b[43mRAGPretrainedModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolbert-ir/colbertv2.0\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.7/envs/olkoa_v3/lib/python3.12/site-packages/ragatouille/RAGPretrainedModel.py:71\u001b[39m, in \u001b[36mRAGPretrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, n_gpu, verbose, index_root)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Load a ColBERT model from a pre-trained checkpoint.\u001b[39;00m\n\u001b[32m     60\u001b[39m \n\u001b[32m     61\u001b[39m \u001b[33;03mParameters:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     68\u001b[39m \u001b[33;03m    cls (RAGPretrainedModel): The current instance of RAGPretrainedModel, with the model initialised.\u001b[39;00m\n\u001b[32m     69\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     70\u001b[39m instance = \u001b[38;5;28mcls\u001b[39m()\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m instance.model = \u001b[43mColBERT\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_gpu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_root\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m instance\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.7/envs/olkoa_v3/lib/python3.12/site-packages/ragatouille/models/colbert.py:84\u001b[39m, in \u001b[36mColBERT.__init__\u001b[39m\u001b[34m(self, pretrained_model_name_or_path, n_gpu, index_name, verbose, load_from_index, training_mode, index_root, **kwargs)\u001b[39m\n\u001b[32m     81\u001b[39m     \u001b[38;5;28mself\u001b[39m.config.root = \u001b[38;5;28mself\u001b[39m.index_root\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m training_mode:\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     \u001b[38;5;28mself\u001b[39m.inference_ckpt = \u001b[43mCheckpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolbert_config\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m     \u001b[38;5;28mself\u001b[39m.base_model_max_tokens = (\n\u001b[32m     88\u001b[39m         \u001b[38;5;28mself\u001b[39m.inference_ckpt.bert.config.max_position_embeddings\n\u001b[32m     89\u001b[39m     ) - \u001b[32m4\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28mself\u001b[39m.run_context = Run().context(\u001b[38;5;28mself\u001b[39m.run_config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.7/envs/olkoa_v3/lib/python3.12/site-packages/colbert/modeling/checkpoint.py:19\u001b[39m, in \u001b[36mCheckpoint.__init__\u001b[39m\u001b[34m(self, name, colbert_config, verbose)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, colbert_config=\u001b[38;5;28;01mNone\u001b[39;00m, verbose:\u001b[38;5;28mint\u001b[39m = \u001b[32m3\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolbert_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.training \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     22\u001b[39m     \u001b[38;5;28mself\u001b[39m.verbose = verbose\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.7/envs/olkoa_v3/lib/python3.12/site-packages/colbert/modeling/colbert.py:24\u001b[39m, in \u001b[36mColBERT.__init__\u001b[39m\u001b[34m(self, name, colbert_config)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(name, colbert_config)\n\u001b[32m     22\u001b[39m \u001b[38;5;28mself\u001b[39m.use_gpu = colbert_config.total_visible_gpus > \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[43mColBERT\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtry_load_torch_extensions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43muse_gpu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.colbert_config.mask_punctuation:\n\u001b[32m     27\u001b[39m     \u001b[38;5;28mself\u001b[39m.skiplist = {w: \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     28\u001b[39m                      \u001b[38;5;28;01mfor\u001b[39;00m symbol \u001b[38;5;129;01min\u001b[39;00m string.punctuation\n\u001b[32m     29\u001b[39m                      \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m [symbol, \u001b[38;5;28mself\u001b[39m.raw_tokenizer.encode(symbol, add_special_tokens=\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[32m0\u001b[39m]]}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.7/envs/olkoa_v3/lib/python3.12/site-packages/colbert/modeling/colbert.py:39\u001b[39m, in \u001b[36mColBERT.try_load_torch_extensions\u001b[39m\u001b[34m(cls, use_gpu)\u001b[39m\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     38\u001b[39m print_message(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m segmented_maxsim_cpp = \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msegmented_maxsim_cpp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m        \u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpathlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[34;43m__file__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msegmented_maxsim.cpp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     44\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextra_cflags\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m-O3\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCOLBERT_LOAD_TORCH_EXTENSION_VERBOSE\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mFalse\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTrue\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[38;5;28mcls\u001b[39m.segmented_maxsim = segmented_maxsim_cpp.segmented_maxsim_cpp\n\u001b[32m     51\u001b[39m \u001b[38;5;28mcls\u001b[39m.loaded_extensions = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.7/envs/olkoa_v3/lib/python3.12/site-packages/torch/utils/cpp_extension.py:1380\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[39m\n\u001b[32m   1288\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(name,\n\u001b[32m   1289\u001b[39m          sources: Union[\u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m]],\n\u001b[32m   1290\u001b[39m          extra_cflags=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1298\u001b[39m          is_standalone=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1299\u001b[39m          keep_intermediates=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m   1300\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1301\u001b[39m \u001b[33;03m    Load a PyTorch C++ extension just-in-time (JIT).\u001b[39;00m\n\u001b[32m   1302\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1378\u001b[39m \u001b[33;03m        ...     verbose=True)\u001b[39;00m\n\u001b[32m   1379\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1380\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_jit_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1381\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1382\u001b[39m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43msources\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1383\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_cflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1384\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1385\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_ldflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1386\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_include_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1387\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_get_build_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1388\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1389\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwith_cuda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1390\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_python_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1391\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_standalone\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1392\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_intermediates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_intermediates\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.7/envs/olkoa_v3/lib/python3.12/site-packages/torch/utils/cpp_extension.py:1815\u001b[39m, in \u001b[36m_jit_compile\u001b[39m\u001b[34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[39m\n\u001b[32m   1813\u001b[39m         baton.release()\n\u001b[32m   1814\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1815\u001b[39m     \u001b[43mbaton\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1817\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[32m   1818\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mLoading extension module \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m'\u001b[39m, file=sys.stderr)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.7/envs/olkoa_v3/lib/python3.12/site-packages/torch/utils/file_baton.py:43\u001b[39m, in \u001b[36mFileBaton.wait\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[33;03mPeriodically sleeps for a certain amount until the baton is released.\u001b[39;00m\n\u001b[32m     38\u001b[39m \n\u001b[32m     39\u001b[39m \u001b[33;03mThe amount of time slept depends on the ``wait_seconds`` parameter\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[33;03mpassed to the constructor.\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m os.path.exists(\u001b[38;5;28mself\u001b[39m.lock_file_path):\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwait_seconds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "rag_model = RAGPretrainedModel.from_pretrained(\"colbert-ir/colbertv2.0\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93fadc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "from dotenv import load_dotenv\n",
    "from botocore.exceptions import ClientError\n",
    "import logging\n",
    "from typing import List, Dict, Any, Optional, Union, BinaryIO\n",
    "import mimetypes\n",
    "\n",
    "import json\n",
    "import io\n",
    "\n",
    "class S3Handler:\n",
    "    \"\"\"\n",
    "    A class to handle common S3 operations using boto3.\n",
    "    This includes listing, creating, deleting buckets and objects,\n",
    "    uploading and downloading files, and generating presigned URLs.\n",
    "    It also supports using environment variables for configuration.\n",
    "    Environment variables:\n",
    "        - S3_ENDPOINT_URL: The endpoint URL for the S3 service\n",
    "        - S3_REGION_NAME: The region name for the S3 service\n",
    "        - SCW_ACCESS_KEY: Access key ID for authentication\n",
    "        - SCW_SECRET_KEY: Secret access key for authentication\n",
    "    Example usage:\n",
    "        s3_handler = S3Handler()\n",
    "        buckets = s3_handler.list_buckets()\n",
    "        print(buckets)\n",
    "        s3_handler.create_bucket('my-new-bucket')\n",
    "        s3_handler.upload_file('local_file.txt', 'my-new-bucket', 's3_file.txt')\n",
    "        url = s3_handler.generate_presigned_url('my-new-bucket', 's3_file.txt')\n",
    "        print(url)\n",
    "        s3_handler.download_file('my-new-bucket', 's3_file.txt', 'downloaded_file.txt')\n",
    "    This class requires the `boto3` and `python-dotenv` packages.\n",
    "    Install them using:\n",
    "        pip install boto3 python-dotenv\n",
    "    Ensure to set the environment variables or pass them as arguments.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, endpoint_url=None, region_name=None,\n",
    "                 access_key_id=None, secret_access_key=None):\n",
    "        \"\"\"\n",
    "        Initialize the S3 handler with optional credentials.\n",
    "        If not provided, will use environment variables.\n",
    "        \"\"\"\n",
    "        # Load environment variables if not done already\n",
    "        load_dotenv()\n",
    "\n",
    "        # Use provided credentials or fall back to environment variables\n",
    "        self.endpoint_url = endpoint_url or os.getenv(\"S3_ENDPOINT_URL\")\n",
    "        self.region_name = region_name or os.getenv(\"S3_REGION_NAME\")\n",
    "        self.access_key_id = access_key_id or os.getenv(\"SCW_ACCESS_KEY\")\n",
    "        self.secret_access_key = secret_access_key or os.getenv(\"SCW_SECRET_KEY\")\n",
    "\n",
    "        # Initialize S3 resource and client\n",
    "        self.s3 = boto3.resource(\n",
    "            service_name='s3',\n",
    "            endpoint_url=self.endpoint_url,\n",
    "            region_name=self.region_name,\n",
    "            aws_access_key_id=self.access_key_id,\n",
    "            aws_secret_access_key=self.secret_access_key\n",
    "        )\n",
    "\n",
    "        self.client = boto3.client(\n",
    "            service_name='s3',\n",
    "            endpoint_url=self.endpoint_url,\n",
    "            region_name=self.region_name,\n",
    "            aws_access_key_id=self.access_key_id,\n",
    "            aws_secret_access_key=self.secret_access_key\n",
    "        )\n",
    "\n",
    "        # Set up logging\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    def list_buckets(self) -> List[str]:\n",
    "        \"\"\"\n",
    "        List all available buckets.\n",
    "\n",
    "        Returns:\n",
    "            List of bucket names\n",
    "        \"\"\"\n",
    "        try:\n",
    "            buckets = [bucket.name for bucket in self.s3.buckets.all()]\n",
    "            return buckets\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error listing buckets: {e}\")\n",
    "            raise\n",
    "\n",
    "    def create_bucket(self, bucket_name: str, region: Optional[str] = None) -> bool:\n",
    "        \"\"\"\n",
    "        Create a new bucket.\n",
    "\n",
    "        Args:\n",
    "            bucket_name: Name of the bucket to create\n",
    "            region: Region to create the bucket in (optional)\n",
    "\n",
    "        Returns:\n",
    "            True if successful, False otherwise\n",
    "        \"\"\"\n",
    "        try:\n",
    "            create_bucket_config = {}\n",
    "            if region and region != 'us-east-1':\n",
    "                create_bucket_config['LocationConstraint'] = region\n",
    "\n",
    "            if create_bucket_config:\n",
    "                self.s3.create_bucket(\n",
    "                    Bucket=bucket_name,\n",
    "                    CreateBucketConfiguration=create_bucket_config\n",
    "                )\n",
    "            else:\n",
    "                self.s3.create_bucket(Bucket=bucket_name)\n",
    "\n",
    "            self.logger.info(f\"Bucket {bucket_name} created successfully\")\n",
    "            return True\n",
    "        except ClientError as e:\n",
    "            self.logger.error(f\"Error creating bucket {bucket_name}: {e}\")\n",
    "            return False\n",
    "\n",
    "    def delete_bucket(self, bucket_name: str, force: bool = False) -> bool:\n",
    "        \"\"\"\n",
    "        Delete a bucket. If force=True, will delete all objects first.\n",
    "\n",
    "        Args:\n",
    "            bucket_name: Name of the bucket to delete\n",
    "            force: If True, delete all objects in the bucket first\n",
    "\n",
    "        Returns:\n",
    "            True if successful, False otherwise\n",
    "        \"\"\"\n",
    "        try:\n",
    "            bucket = self.s3.Bucket(bucket_name)\n",
    "\n",
    "            if force:\n",
    "                bucket.objects.all().delete()\n",
    "\n",
    "            bucket.delete()\n",
    "            self.logger.info(f\"Bucket {bucket_name} deleted successfully\")\n",
    "            return True\n",
    "        except ClientError as e:\n",
    "            self.logger.error(f\"Error deleting bucket {bucket_name}: {e}\")\n",
    "            return False\n",
    "\n",
    "    def list_objects(self, bucket_name: str, prefix: str = '') -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        List objects in a bucket with optional prefix filter.\n",
    "\n",
    "        Args:\n",
    "            bucket_name: Name of the bucket\n",
    "            prefix: Prefix to filter objects by\n",
    "\n",
    "        Returns:\n",
    "            List of objects with key, size, last_modified\n",
    "        \"\"\"\n",
    "        try:\n",
    "            bucket = self.s3.Bucket(bucket_name)\n",
    "            objects = []\n",
    "\n",
    "            for obj in bucket.objects.filter(Prefix=prefix):\n",
    "                objects.append({\n",
    "                    'key': obj.key,\n",
    "                    'size': obj.size,\n",
    "                    'last_modified': obj.last_modified\n",
    "                })\n",
    "\n",
    "            return objects\n",
    "        except ClientError as e:\n",
    "            self.logger.error(f\"Error listing objects in bucket {bucket_name}: {e}\")\n",
    "            raise\n",
    "\n",
    "    def upload_file(self, file_path: str, bucket_name: str,\n",
    "                   object_key: Optional[str] = None,\n",
    "                   extra_args: Optional[Dict[str, Any]] = None) -> bool:\n",
    "        \"\"\"\n",
    "        Upload a file to S3.\n",
    "\n",
    "        Args:\n",
    "            file_path: Path to the local file\n",
    "            bucket_name: Name of the bucket\n",
    "            object_key: Key to use in S3 (defaults to filename if not provided)\n",
    "            extra_args: Additional arguments for upload (ContentType, ACL, etc.)\n",
    "\n",
    "        Returns:\n",
    "            True if successful, False otherwise\n",
    "        \"\"\"\n",
    "        if not object_key:\n",
    "            object_key = os.path.basename(file_path)\n",
    "\n",
    "        # Determine content type if not specified in extra_args\n",
    "        if extra_args is None:\n",
    "            extra_args = {}\n",
    "\n",
    "        if 'ContentType' not in extra_args:\n",
    "            content_type, _ = mimetypes.guess_type(file_path)\n",
    "            if content_type:\n",
    "                extra_args['ContentType'] = content_type\n",
    "\n",
    "        try:\n",
    "            self.s3.meta.client.upload_file(\n",
    "                file_path, bucket_name, object_key, ExtraArgs=extra_args\n",
    "            )\n",
    "            self.logger.info(f\"File {file_path} uploaded to {bucket_name}/{object_key}\")\n",
    "            return True\n",
    "        except ClientError as e:\n",
    "            self.logger.error(f\"Error uploading file {file_path}: {e}\")\n",
    "            return False\n",
    "\n",
    "    def upload_directory(self, local_dir, bucket_name, s3_prefix):\n",
    "        \"\"\"\n",
    "        Upload a directory and all its contents to S3, preserving the folder structure.\n",
    "\n",
    "        Args:\n",
    "            local_dir: Path to local directory\n",
    "            bucket_name: Name of the S3 bucket\n",
    "            s3_prefix: Prefix in S3 where files should be uploaded\n",
    "        \"\"\"\n",
    "        # First, collect all files to determine total size\n",
    "        all_files = []\n",
    "        total_size = 0\n",
    "\n",
    "        for root, dirs, files in os.walk(local_dir):\n",
    "            for file in files:\n",
    "                local_file_path = os.path.join(root, file)\n",
    "                file_size = os.path.getsize(local_file_path)\n",
    "                relative_path = os.path.relpath(local_file_path, local_dir)\n",
    "                s3_key = os.path.join(s3_prefix, relative_path).replace(\"\\\\\", \"/\")\n",
    "                all_files.append((local_file_path, s3_key, file_size))\n",
    "                total_size += file_size\n",
    "\n",
    "        if not all_files:\n",
    "            print(\"No files found to upload.\")\n",
    "            return\n",
    "\n",
    "        # Create a progress callback\n",
    "        uploaded_size = 0\n",
    "\n",
    "        def progress_callback(bytes_transferred):\n",
    "            nonlocal uploaded_size\n",
    "            uploaded_size += bytes_transferred\n",
    "            percent = min(100, int(uploaded_size * 100 / total_size))\n",
    "            progress_bar = f\"[{'#' * (percent // 2)}{' ' * (50 - (percent // 2))}]\"\n",
    "            print(f\"\\rUploading: {progress_bar} {percent}% ({uploaded_size/1024/1024:.2f} MB / {total_size/1024/1024:.2f} MB)\", end=\"\")\n",
    "\n",
    "        # Upload files with progress tracking\n",
    "        print(f\"Uploading {len(all_files)} files ({total_size/1024/1024:.2f} MB) to {bucket_name}/{s3_prefix}\")\n",
    "\n",
    "        for idx, (local_file_path, s3_key, _) in enumerate(all_files, 1):\n",
    "            try:\n",
    "                # Create a callback configuration for this file\n",
    "                callback = boto3.s3.transfer.S3Transfer.ALLOWED_UPLOAD_ARGS['Callback']\n",
    "                extra_args = {'Callback': progress_callback}\n",
    "\n",
    "                # Upload the file\n",
    "                self.s3.meta.client.upload_file(\n",
    "                    local_file_path, bucket_name, s3_key,\n",
    "                    ExtraArgs=extra_args\n",
    "                )\n",
    "\n",
    "                # Update progress\n",
    "                print(f\"\\rUploaded [{idx}/{len(all_files)}]: {local_file_path} to {bucket_name}/{s3_key}\")\n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Error uploading {local_file_path}: {e}\")\n",
    "\n",
    "        print(f\"\\nUpload complete! {len(all_files)} files ({total_size/1024/1024:.2f} MB) uploaded to {bucket_name}/{s3_prefix}\")\n",
    "\n",
    "    def upload_fileobj(self, file_obj: BinaryIO, bucket_name: str,\n",
    "                      object_key: str,\n",
    "                      extra_args: Optional[Dict[str, Any]] = None) -> bool:\n",
    "        \"\"\"\n",
    "        Upload a file-like object to S3.\n",
    "\n",
    "        Args:\n",
    "            file_obj: File-like object to upload\n",
    "            bucket_name: Name of the bucket\n",
    "            object_key: Key to use in S3\n",
    "            extra_args: Additional arguments for upload (ContentType, ACL, etc.)\n",
    "\n",
    "        Returns:\n",
    "            True if successful, False otherwise\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.s3.meta.client.upload_fileobj(\n",
    "                file_obj, bucket_name, object_key, ExtraArgs=extra_args or {}\n",
    "            )\n",
    "            self.logger.info(f\"File object uploaded to {bucket_name}/{object_key}\")\n",
    "            return True\n",
    "        except ClientError as e:\n",
    "            self.logger.error(f\"Error uploading file object: {e}\")\n",
    "            return False\n",
    "\n",
    "    def download_file(self, bucket_name: str, object_key: str,\n",
    "                     file_path: str) -> bool:\n",
    "        \"\"\"\n",
    "        Download a file from S3.\n",
    "\n",
    "        Args:\n",
    "            bucket_name: Name of the bucket\n",
    "            object_key: Key of the object in S3\n",
    "            file_path: Path to save the file locally\n",
    "\n",
    "        Returns:\n",
    "            True if successful, False otherwise\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Ensure directory exists\n",
    "            os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "\n",
    "            self.s3.meta.client.download_file(\n",
    "                bucket_name, object_key, file_path\n",
    "            )\n",
    "            self.logger.info(f\"File {bucket_name}/{object_key} downloaded to {file_path}\")\n",
    "            return True\n",
    "        except ClientError as e:\n",
    "            self.logger.error(f\"Error downloading file {bucket_name}/{object_key}: {e}\")\n",
    "            return False\n",
    "\n",
    "    def download_directory(self, bucket_name: str, s3_prefix: str, local_dir: str) -> bool:\n",
    "        \"\"\"\n",
    "        Download all files with a specific prefix (S3 folder) to a local directory.\n",
    "\n",
    "        Args:\n",
    "            bucket_name: Name of the bucket\n",
    "            s3_prefix: Prefix/folder path in S3 to download\n",
    "            local_dir: Local directory to save files\n",
    "\n",
    "        Returns:\n",
    "            True if all files downloaded successfully, False otherwise\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # List all objects with the given prefix\n",
    "            objects = self.list_objects(bucket_name, s3_prefix)\n",
    "\n",
    "            if not objects:\n",
    "                self.logger.warning(f\"No objects found with prefix {s3_prefix} in bucket {bucket_name}\")\n",
    "                return False\n",
    "\n",
    "            # Calculate total size for progress tracking\n",
    "            total_size = sum(obj['size'] for obj in objects)\n",
    "            downloaded_size = 0\n",
    "\n",
    "            print(f\"Downloading {len(objects)} files ({total_size/1024/1024:.2f} MB) from {bucket_name}/{s3_prefix}\")\n",
    "\n",
    "            # Create download callback\n",
    "            def progress_callback(bytes_transferred):\n",
    "                nonlocal downloaded_size\n",
    "                downloaded_size += bytes_transferred\n",
    "                percent = min(100, int(downloaded_size * 100 / total_size)) if total_size > 0 else 0\n",
    "                progress_bar = f\"[{'#' * (percent // 2)}{' ' * (50 - (percent // 2))}]\"\n",
    "                print(f\"\\rDownloading: {progress_bar} {percent}% ({downloaded_size/1024/1024:.2f} MB / {total_size/1024/1024:.2f} MB)\", end=\"\")\n",
    "\n",
    "            # Download each object\n",
    "            success_count = 0\n",
    "            for idx, obj in enumerate(objects, 1):\n",
    "                try:\n",
    "                    # Determine the local file path\n",
    "                    # Remove the common prefix to maintain directory structure\n",
    "                    relative_path = obj['key']\n",
    "                    if s3_prefix and relative_path.startswith(s3_prefix):\n",
    "                        relative_path = relative_path[len(s3_prefix):].lstrip('/')\n",
    "\n",
    "                    local_file_path = os.path.join(local_dir, relative_path)\n",
    "\n",
    "                    # Ensure directory exists\n",
    "                    os.makedirs(os.path.dirname(local_file_path), exist_ok=True)\n",
    "\n",
    "                    # Download with progress callback\n",
    "                    transfer_config = boto3.s3.transfer.TransferConfig(\n",
    "                        use_threads=True,\n",
    "                        max_concurrency=10\n",
    "                    )\n",
    "                    transfer = boto3.s3.transfer.S3Transfer(\n",
    "                        self.client,\n",
    "                        config=transfer_config\n",
    "                    )\n",
    "\n",
    "                    transfer.download_file(\n",
    "                        bucket_name, obj['key'], local_file_path,\n",
    "                        callback=progress_callback\n",
    "                    )\n",
    "\n",
    "                    success_count += 1\n",
    "                    print(f\"\\rDownloaded [{idx}/{len(objects)}]: {obj['key']} to {local_file_path}\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    self.logger.error(f\"Error downloading {obj['key']}: {e}\")\n",
    "\n",
    "            print(f\"\\nDownload complete! {success_count}/{len(objects)} files ({downloaded_size/1024/1024:.2f} MB) downloaded to {local_dir}\")\n",
    "            return success_count == len(objects)\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error downloading directory {s3_prefix} from {bucket_name}: {e}\")\n",
    "            return False\n",
    "\n",
    "    def get_object(self, bucket_name: str, object_key: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Get an object and its metadata from S3.\n",
    "\n",
    "        Args:\n",
    "            bucket_name: Name of the bucket\n",
    "            object_key: Key of the object in S3\n",
    "\n",
    "        Returns:\n",
    "            Dictionary with object content and metadata\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = self.client.get_object(Bucket=bucket_name, Key=object_key)\n",
    "            return {\n",
    "                'Body': response['Body'].read(),\n",
    "                'ContentType': response.get('ContentType'),\n",
    "                'ContentLength': response.get('ContentLength'),\n",
    "                'LastModified': response.get('LastModified'),\n",
    "                'Metadata': response.get('Metadata', {})\n",
    "            }\n",
    "        except ClientError as e:\n",
    "            self.logger.error(f\"Error getting object {bucket_name}/{object_key}: {e}\")\n",
    "            raise\n",
    "\n",
    "    def delete_object(self, bucket_name: str, object_key: str) -> bool:\n",
    "        \"\"\"\n",
    "        Delete an object from S3.\n",
    "\n",
    "        Args:\n",
    "            bucket_name: Name of the bucket\n",
    "            object_key: Key of the object in S3\n",
    "\n",
    "        Returns:\n",
    "            True if successful, False otherwise\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.s3.Object(bucket_name, object_key).delete()\n",
    "            self.logger.info(f\"Object {bucket_name}/{object_key} deleted successfully\")\n",
    "            return True\n",
    "        except ClientError as e:\n",
    "            self.logger.error(f\"Error deleting object {bucket_name}/{object_key}: {e}\")\n",
    "            return False\n",
    "\n",
    "    def delete_objects(self, bucket_name: str, object_keys: List[str]) -> Dict[str, List[str]]:\n",
    "        \"\"\"\n",
    "        Delete multiple objects from S3 in a single request.\n",
    "\n",
    "        Args:\n",
    "            bucket_name: Name of the bucket\n",
    "            object_keys: List of object keys to delete\n",
    "\n",
    "        Returns:\n",
    "            Dictionary with 'Deleted' and 'Errors' lists\n",
    "        \"\"\"\n",
    "        if not object_keys:\n",
    "            return {'Deleted': [], 'Errors': []}\n",
    "\n",
    "        try:\n",
    "            objects = [{'Key': key} for key in object_keys]\n",
    "            response = self.client.delete_objects(\n",
    "                Bucket=bucket_name,\n",
    "                Delete={'Objects': objects}\n",
    "            )\n",
    "\n",
    "            deleted = [obj.get('Key') for obj in response.get('Deleted', [])]\n",
    "            errors = [f\"{err.get('Key')}: {err.get('Message')}\" for err in response.get('Errors', [])]\n",
    "\n",
    "            if deleted:\n",
    "                self.logger.info(f\"Deleted {len(deleted)} objects from {bucket_name}\")\n",
    "            if errors:\n",
    "                self.logger.warning(f\"Failed to delete {len(errors)} objects from {bucket_name}\")\n",
    "\n",
    "            return {\n",
    "                'Deleted': deleted,\n",
    "                'Errors': errors\n",
    "            }\n",
    "        except ClientError as e:\n",
    "            self.logger.error(f\"Error batch deleting objects from {bucket_name}: {e}\")\n",
    "            raise\n",
    "\n",
    "    def copy_object(self, source_bucket: str, source_key: str,\n",
    "                   dest_bucket: str, dest_key: str) -> bool:\n",
    "        \"\"\"\n",
    "        Copy an object within S3.\n",
    "\n",
    "        Args:\n",
    "            source_bucket: Source bucket name\n",
    "            source_key: Source object key\n",
    "            dest_bucket: Destination bucket name\n",
    "            dest_key: Destination object key\n",
    "\n",
    "        Returns:\n",
    "            True if successful, False otherwise\n",
    "        \"\"\"\n",
    "        try:\n",
    "            copy_source = {\n",
    "                'Bucket': source_bucket,\n",
    "                'Key': source_key\n",
    "            }\n",
    "            self.s3.meta.client.copy(copy_source, dest_bucket, dest_key)\n",
    "            self.logger.info(f\"Object {source_bucket}/{source_key} copied to {dest_bucket}/{dest_key}\")\n",
    "            return True\n",
    "        except ClientError as e:\n",
    "            self.logger.error(f\"Error copying object: {e}\")\n",
    "            return False\n",
    "\n",
    "    def generate_presigned_url(self, bucket_name: str, object_key: str,\n",
    "                              expiration: int = 3600, http_method: str = 'GET') -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Generate a presigned URL for an S3 object.\n",
    "\n",
    "        Args:\n",
    "            bucket_name: Name of the bucket\n",
    "            object_key: Key of the object in S3\n",
    "            expiration: Time in seconds until the URL expires\n",
    "            http_method: HTTP method to allow ('GET', 'PUT')\n",
    "\n",
    "        Returns:\n",
    "            Presigned URL or None if error\n",
    "        \"\"\"\n",
    "        try:\n",
    "            url = self.client.generate_presigned_url(\n",
    "                'get_object' if http_method == 'GET' else 'put_object',\n",
    "                Params={'Bucket': bucket_name, 'Key': object_key},\n",
    "                ExpiresIn=expiration\n",
    "            )\n",
    "            return url\n",
    "        except ClientError as e:\n",
    "            self.logger.error(f\"Error generating presigned URL: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93e0bee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example usage\n",
    "#         # \"\"\"\n",
    "#         # Upload a directory and all its contents to S3, preserving the folder structure.\n",
    "\n",
    "#         # Args:\n",
    "#         #     local_dir: Path to local directory\n",
    "#         #     bucket_name: Name of the S3 bucket\n",
    "#         #     s3_prefix: Prefix in S3 where files should be uploaded\n",
    "#         # \"\"\"\n",
    "\n",
    "# s3_handler = S3Handler()\n",
    "# local_directory = \"data/Projects/Projet Demo/Boîte mail de Céline/processed/celine.guyon\"\n",
    "# bucket_name = \"olkoa-celine\"\n",
    "# s3_prefix = \"\"\n",
    "\n",
    "# s3_handler.upload_directory(local_directory, bucket_name, s3_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48952faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- highco\n",
      "- olkoa-celine\n",
      "- olkoa-joel\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m bucket \u001b[38;5;129;01min\u001b[39;00m buckets:\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbucket\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43ms3_handler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlist_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43molkoa-celine\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m objects = s3_handler.list_objects(\u001b[33m\"\u001b[39m\u001b[33molkoa-celine\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m objects:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 157\u001b[39m, in \u001b[36mS3Handler.list_objects\u001b[39m\u001b[34m(self, bucket_name, prefix)\u001b[39m\n\u001b[32m    154\u001b[39m bucket = \u001b[38;5;28mself\u001b[39m.s3.Bucket(bucket_name)\n\u001b[32m    155\u001b[39m objects = []\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbucket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mobjects\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPrefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobjects\u001b[49m\u001b[43m.\u001b[49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mkey\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msize\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlast_modified\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlast_modified\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m objects\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/boto3/resources/collection.py:79\u001b[39m, in \u001b[36mResourceCollection.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     76\u001b[39m limit = \u001b[38;5;28mself\u001b[39m._params.get(\u001b[33m'\u001b[39m\u001b[33mlimit\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     78\u001b[39m count = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpages\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpage\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/boto3/resources/collection.py:169\u001b[39m, in \u001b[36mResourceCollection.pages\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    166\u001b[39m \u001b[38;5;66;03m# Now that we have a page iterator or single page of results\u001b[39;00m\n\u001b[32m    167\u001b[39m \u001b[38;5;66;03m# we start processing and yielding individual items.\u001b[39;00m\n\u001b[32m    168\u001b[39m count = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpages\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpage_items\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpage\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/botocore/paginate.py:272\u001b[39m, in \u001b[36mPageIterator.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    270\u001b[39m \u001b[38;5;28mself\u001b[39m._inject_starting_params(current_kwargs)\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    273\u001b[39m     parsed = \u001b[38;5;28mself\u001b[39m._extract_parsed_response(response)\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m first_request:\n\u001b[32m    275\u001b[39m         \u001b[38;5;66;03m# The first request is handled differently.  We could\u001b[39;00m\n\u001b[32m    276\u001b[39m         \u001b[38;5;66;03m# possibly have a resume/starting token that tells us where\u001b[39;00m\n\u001b[32m    277\u001b[39m         \u001b[38;5;66;03m# to index into the retrieved page.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/botocore/context.py:123\u001b[39m, in \u001b[36mwith_current_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hook:\n\u001b[32m    122\u001b[39m     hook()\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/botocore/paginate.py:361\u001b[39m, in \u001b[36mPageIterator._make_request\u001b[39m\u001b[34m(self, current_kwargs)\u001b[39m\n\u001b[32m    359\u001b[39m \u001b[38;5;129m@with_current_context\u001b[39m(partial(register_feature_id, \u001b[33m'\u001b[39m\u001b[33mPAGINATOR\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m    360\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_make_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, current_kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m361\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcurrent_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/botocore/client.py:595\u001b[39m, in \u001b[36mClientCreator._create_api_method.<locals>._api_call\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    591\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    592\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m() only accepts keyword arguments.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    593\u001b[39m     )\n\u001b[32m    594\u001b[39m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m595\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/botocore/context.py:123\u001b[39m, in \u001b[36mwith_current_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hook:\n\u001b[32m    122\u001b[39m     hook()\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/botocore/client.py:1040\u001b[39m, in \u001b[36mBaseClient._make_api_call\u001b[39m\u001b[34m(self, operation_name, api_params)\u001b[39m\n\u001b[32m   1036\u001b[39m     maybe_compress_request(\n\u001b[32m   1037\u001b[39m         \u001b[38;5;28mself\u001b[39m.meta.config, request_dict, operation_model\n\u001b[32m   1038\u001b[39m     )\n\u001b[32m   1039\u001b[39m     apply_request_checksum(request_dict)\n\u001b[32m-> \u001b[39m\u001b[32m1040\u001b[39m     http, parsed_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1041\u001b[39m \u001b[43m        \u001b[49m\u001b[43moperation_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_context\u001b[49m\n\u001b[32m   1042\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1044\u001b[39m \u001b[38;5;28mself\u001b[39m.meta.events.emit(\n\u001b[32m   1045\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mafter-call.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mservice_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moperation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m,\n\u001b[32m   1046\u001b[39m     http_response=http,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1049\u001b[39m     context=request_context,\n\u001b[32m   1050\u001b[39m )\n\u001b[32m   1052\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http.status_code >= \u001b[32m300\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/botocore/client.py:1064\u001b[39m, in \u001b[36mBaseClient._make_request\u001b[39m\u001b[34m(self, operation_model, request_dict, request_context)\u001b[39m\n\u001b[32m   1062\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_make_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, operation_model, request_dict, request_context):\n\u001b[32m   1063\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1064\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_endpoint\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmake_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1065\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1066\u001b[39m         \u001b[38;5;28mself\u001b[39m.meta.events.emit(\n\u001b[32m   1067\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mafter-call-error.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._service_model.service_id.hyphenize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moperation_model.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m,\n\u001b[32m   1068\u001b[39m             exception=e,\n\u001b[32m   1069\u001b[39m             context=request_context,\n\u001b[32m   1070\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/botocore/endpoint.py:119\u001b[39m, in \u001b[36mEndpoint.make_request\u001b[39m\u001b[34m(self, operation_model, request_dict)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmake_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, operation_model, request_dict):\n\u001b[32m    114\u001b[39m     logger.debug(\n\u001b[32m    115\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMaking request for \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m with params: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    116\u001b[39m         operation_model,\n\u001b[32m    117\u001b[39m         request_dict,\n\u001b[32m    118\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/botocore/endpoint.py:197\u001b[39m, in \u001b[36mEndpoint._send_request\u001b[39m\u001b[34m(self, request_dict, operation_model)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;28mself\u001b[39m._update_retries_context(context, attempts)\n\u001b[32m    196\u001b[39m request = \u001b[38;5;28mself\u001b[39m.create_request(request_dict, operation_model)\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m success_response, exception = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._needs_retry(\n\u001b[32m    201\u001b[39m     attempts,\n\u001b[32m    202\u001b[39m     operation_model,\n\u001b[32m   (...)\u001b[39m\u001b[32m    205\u001b[39m     exception,\n\u001b[32m    206\u001b[39m ):\n\u001b[32m    207\u001b[39m     attempts += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/botocore/endpoint.py:239\u001b[39m, in \u001b[36mEndpoint._get_response\u001b[39m\u001b[34m(self, request, operation_model, context)\u001b[39m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_response\u001b[39m(\u001b[38;5;28mself\u001b[39m, request, operation_model, context):\n\u001b[32m    234\u001b[39m     \u001b[38;5;66;03m# This will return a tuple of (success_response, exception)\u001b[39;00m\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# and success_response is itself a tuple of\u001b[39;00m\n\u001b[32m    236\u001b[39m     \u001b[38;5;66;03m# (http_response, parsed_dict).\u001b[39;00m\n\u001b[32m    237\u001b[39m     \u001b[38;5;66;03m# If an exception occurs then the success_response is None.\u001b[39;00m\n\u001b[32m    238\u001b[39m     \u001b[38;5;66;03m# If no exception occurs then exception is None.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m     success_response, exception = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_get_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    242\u001b[39m     kwargs_to_emit = {\n\u001b[32m    243\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mresponse_dict\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    244\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mparsed_response\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    245\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mcontext\u001b[39m\u001b[33m'\u001b[39m: context,\n\u001b[32m    246\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mexception\u001b[39m\u001b[33m'\u001b[39m: exception,\n\u001b[32m    247\u001b[39m     }\n\u001b[32m    248\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m success_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/botocore/endpoint.py:313\u001b[39m, in \u001b[36mEndpoint._do_get_response\u001b[39m\u001b[34m(self, request, operation_model, context)\u001b[39m\n\u001b[32m    306\u001b[39m \u001b[38;5;28mself\u001b[39m._event_emitter.emit(\n\u001b[32m    307\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbefore-parse.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mservice_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moperation_model.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    308\u001b[39m     operation_model=operation_model,\n\u001b[32m    309\u001b[39m     response_dict=response_dict,\n\u001b[32m    310\u001b[39m     customized_response_dict=customized_response_dict,\n\u001b[32m    311\u001b[39m )\n\u001b[32m    312\u001b[39m parser = \u001b[38;5;28mself\u001b[39m._response_parser_factory.create_parser(protocol)\n\u001b[32m--> \u001b[39m\u001b[32m313\u001b[39m parsed_response = \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutput_shape\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    316\u001b[39m parsed_response.update(customized_response_dict)\n\u001b[32m    317\u001b[39m \u001b[38;5;66;03m# Do a second parsing pass to pick up on any modeled error fields\u001b[39;00m\n\u001b[32m    318\u001b[39m \u001b[38;5;66;03m# NOTE: Ideally, we would push this down into the parser classes but\u001b[39;00m\n\u001b[32m    319\u001b[39m \u001b[38;5;66;03m# they currently have no reference to the operation or service model\u001b[39;00m\n\u001b[32m    320\u001b[39m \u001b[38;5;66;03m# The parsers should probably take the operation model instead of\u001b[39;00m\n\u001b[32m    321\u001b[39m \u001b[38;5;66;03m# output shape but we can't change that now\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/botocore/parsers.py:262\u001b[39m, in \u001b[36mResponseParser.parse\u001b[39m\u001b[34m(self, response, shape)\u001b[39m\n\u001b[32m    260\u001b[39m         parsed = \u001b[38;5;28mself\u001b[39m._do_error_parse(response, shape)\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     parsed = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[38;5;66;03m# We don't want to decorate event stream responses with metadata\u001b[39;00m\n\u001b[32m    265\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mand\u001b[39;00m shape.serialization.get(\u001b[33m'\u001b[39m\u001b[33meventstream\u001b[39m\u001b[33m'\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/botocore/parsers.py:1114\u001b[39m, in \u001b[36mBaseRestParser._do_parse\u001b[39m\u001b[34m(self, response, shape)\u001b[39m\n\u001b[32m   1110\u001b[39m final_parsed = {}\n\u001b[32m   1111\u001b[39m final_parsed[\u001b[33m'\u001b[39m\u001b[33mResponseMetadata\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28mself\u001b[39m._populate_response_metadata(\n\u001b[32m   1112\u001b[39m     response\n\u001b[32m   1113\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1114\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_add_modeled_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_parsed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1115\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m final_parsed\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/botocore/parsers.py:1124\u001b[39m, in \u001b[36mBaseRestParser._add_modeled_parse\u001b[39m\u001b[34m(self, response, shape, final_parsed)\u001b[39m\n\u001b[32m   1120\u001b[39m member_shapes = shape.members\n\u001b[32m   1121\u001b[39m \u001b[38;5;28mself\u001b[39m._parse_non_payload_attrs(\n\u001b[32m   1122\u001b[39m     response, shape, member_shapes, final_parsed\n\u001b[32m   1123\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1124\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse_payload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmember_shapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_parsed\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/botocore/parsers.py:1166\u001b[39m, in \u001b[36mBaseRestParser._parse_payload\u001b[39m\u001b[34m(self, response, shape, member_shapes, final_parsed)\u001b[39m\n\u001b[32m   1164\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1165\u001b[39m     original_parsed = \u001b[38;5;28mself\u001b[39m._initial_body_parse(response[\u001b[33m'\u001b[39m\u001b[33mbody\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m1166\u001b[39m     body_parsed = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_parsed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1167\u001b[39m     final_parsed.update(body_parsed)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/botocore/parsers.py:342\u001b[39m, in \u001b[36mResponseParser._parse_shape\u001b[39m\u001b[34m(self, shape, node)\u001b[39m\n\u001b[32m    338\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_parse_shape\u001b[39m(\u001b[38;5;28mself\u001b[39m, shape, node):\n\u001b[32m    339\u001b[39m     handler = \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[32m    340\u001b[39m         \u001b[38;5;28mself\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m_handle_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape.type_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m, \u001b[38;5;28mself\u001b[39m._default_handle\n\u001b[32m    341\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m342\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/botocore/parsers.py:471\u001b[39m, in \u001b[36mBaseXMLResponseParser._handle_structure\u001b[39m\u001b[34m(self, shape, node)\u001b[39m\n\u001b[32m    469\u001b[39m member_node = xml_dict.get(xml_name)\n\u001b[32m    470\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m member_node \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m471\u001b[39m     parsed[member_name] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse_shape\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmember_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmember_node\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m member_shape.serialization.get(\u001b[33m'\u001b[39m\u001b[33mxmlAttribute\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    475\u001b[39m     attribs = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/botocore/parsers.py:342\u001b[39m, in \u001b[36mResponseParser._parse_shape\u001b[39m\u001b[34m(self, shape, node)\u001b[39m\n\u001b[32m    338\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_parse_shape\u001b[39m(\u001b[38;5;28mself\u001b[39m, shape, node):\n\u001b[32m    339\u001b[39m     handler = \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[32m    340\u001b[39m         \u001b[38;5;28mself\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m_handle_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape.type_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m, \u001b[38;5;28mself\u001b[39m._default_handle\n\u001b[32m    341\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m342\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/botocore/parsers.py:1225\u001b[39m, in \u001b[36mBaseRestParser._handle_list\u001b[39m\u001b[34m(self, shape, node)\u001b[39m\n\u001b[32m   1222\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m location == \u001b[33m'\u001b[39m\u001b[33mheader\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m   1223\u001b[39m     \u001b[38;5;66;03m# List in headers may be a comma separated string as per RFC7230\u001b[39;00m\n\u001b[32m   1224\u001b[39m     node = [e.strip() \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m node.split(\u001b[33m'\u001b[39m\u001b[33m,\u001b[39m\u001b[33m'\u001b[39m)]\n\u001b[32m-> \u001b[39m\u001b[32m1225\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/botocore/parsers.py:448\u001b[39m, in \u001b[36mBaseXMLResponseParser._handle_list\u001b[39m\u001b[34m(self, shape, node)\u001b[39m\n\u001b[32m    446\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shape.serialization.get(\u001b[33m'\u001b[39m\u001b[33mflattened\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m    447\u001b[39m     node = [node]\n\u001b[32m--> \u001b[39m\u001b[32m448\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/botocore/parsers.py:350\u001b[39m, in \u001b[36mResponseParser._handle_list\u001b[39m\u001b[34m(self, shape, node)\u001b[39m\n\u001b[32m    348\u001b[39m member_shape = shape.member\n\u001b[32m    349\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m node:\n\u001b[32m--> \u001b[39m\u001b[32m350\u001b[39m     parsed.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmember_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    351\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m parsed\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/botocore/parsers.py:342\u001b[39m, in \u001b[36mResponseParser._parse_shape\u001b[39m\u001b[34m(self, shape, node)\u001b[39m\n\u001b[32m    338\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_parse_shape\u001b[39m(\u001b[38;5;28mself\u001b[39m, shape, node):\n\u001b[32m    339\u001b[39m     handler = \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[32m    340\u001b[39m         \u001b[38;5;28mself\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m_handle_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape.type_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m, \u001b[38;5;28mself\u001b[39m._default_handle\n\u001b[32m    341\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m342\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/botocore/parsers.py:471\u001b[39m, in \u001b[36mBaseXMLResponseParser._handle_structure\u001b[39m\u001b[34m(self, shape, node)\u001b[39m\n\u001b[32m    469\u001b[39m member_node = xml_dict.get(xml_name)\n\u001b[32m    470\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m member_node \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m471\u001b[39m     parsed[member_name] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse_shape\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmember_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmember_node\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m member_shape.serialization.get(\u001b[33m'\u001b[39m\u001b[33mxmlAttribute\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    475\u001b[39m     attribs = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/botocore/parsers.py:342\u001b[39m, in \u001b[36mResponseParser._parse_shape\u001b[39m\u001b[34m(self, shape, node)\u001b[39m\n\u001b[32m    338\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_parse_shape\u001b[39m(\u001b[38;5;28mself\u001b[39m, shape, node):\n\u001b[32m    339\u001b[39m     handler = \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[32m    340\u001b[39m         \u001b[38;5;28mself\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m_handle_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape.type_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m, \u001b[38;5;28mself\u001b[39m._default_handle\n\u001b[32m    341\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m342\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/botocore/parsers.py:188\u001b[39m, in \u001b[36m_text_content.<locals>._get_text_content\u001b[39m\u001b[34m(self, shape, node_or_string)\u001b[39m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    187\u001b[39m     text = node_or_string\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/botocore/parsers.py:568\u001b[39m, in \u001b[36mBaseXMLResponseParser._handle_timestamp\u001b[39m\u001b[34m(self, shape, text)\u001b[39m\n\u001b[32m    566\u001b[39m \u001b[38;5;129m@_text_content\u001b[39m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_handle_timestamp\u001b[39m(\u001b[38;5;28mself\u001b[39m, shape, text):\n\u001b[32m--> \u001b[39m\u001b[32m568\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_timestamp_parser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/botocore/utils.py:966\u001b[39m, in \u001b[36mparse_timestamp\u001b[39m\u001b[34m(value)\u001b[39m\n\u001b[32m    964\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m tzinfo \u001b[38;5;129;01min\u001b[39;00m tzinfo_options:\n\u001b[32m    965\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m966\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse_timestamp_with_tzinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtzinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    967\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mOverflowError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    968\u001b[39m         logger.debug(\n\u001b[32m    969\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mUnable to parse timestamp with \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m timezone info.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    970\u001b[39m             tzinfo.\u001b[34m__name__\u001b[39m,\n\u001b[32m    971\u001b[39m             exc_info=e,\n\u001b[32m    972\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/botocore/utils.py:946\u001b[39m, in \u001b[36m_parse_timestamp_with_tzinfo\u001b[39m\u001b[34m(value, tzinfo)\u001b[39m\n\u001b[32m    941\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    942\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    943\u001b[39m     \u001b[38;5;66;03m# In certain cases, a timestamp marked with GMT can be parsed into a\u001b[39;00m\n\u001b[32m    944\u001b[39m     \u001b[38;5;66;03m# different time zone, so here we provide a context which will\u001b[39;00m\n\u001b[32m    945\u001b[39m     \u001b[38;5;66;03m# enforce that GMT == UTC.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m946\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdateutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtzinfos\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mGMT\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtzutc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    948\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mInvalid timestamp \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/dateutil/parser/_parser.py:1368\u001b[39m, in \u001b[36mparse\u001b[39m\u001b[34m(timestr, parserinfo, **kwargs)\u001b[39m\n\u001b[32m   1366\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser(parserinfo).parse(timestr, **kwargs)\n\u001b[32m   1367\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1368\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDEFAULTPARSER\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimestr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/dateutil/parser/_parser.py:640\u001b[39m, in \u001b[36mparser.parse\u001b[39m\u001b[34m(self, timestr, default, ignoretz, tzinfos, **kwargs)\u001b[39m\n\u001b[32m    636\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m default \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    637\u001b[39m     default = datetime.datetime.now().replace(hour=\u001b[32m0\u001b[39m, minute=\u001b[32m0\u001b[39m,\n\u001b[32m    638\u001b[39m                                               second=\u001b[32m0\u001b[39m, microsecond=\u001b[32m0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m640\u001b[39m res, skipped_tokens = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimestr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    642\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    643\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ParserError(\u001b[33m\"\u001b[39m\u001b[33mUnknown string format: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, timestr)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/dateutil/parser/_parser.py:719\u001b[39m, in \u001b[36mparser._parse\u001b[39m\u001b[34m(self, timestr, dayfirst, yearfirst, fuzzy, fuzzy_with_tokens)\u001b[39m\n\u001b[32m    716\u001b[39m     yearfirst = info.yearfirst\n\u001b[32m    718\u001b[39m res = \u001b[38;5;28mself\u001b[39m._result()\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m l = \u001b[43m_timelex\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimestr\u001b[49m\u001b[43m)\u001b[49m         \u001b[38;5;66;03m# Splits the timestr into tokens\u001b[39;00m\n\u001b[32m    721\u001b[39m skipped_idxs = []\n\u001b[32m    723\u001b[39m \u001b[38;5;66;03m# year/month/day list\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/dateutil/parser/_parser.py:201\u001b[39m, in \u001b[36m_timelex.split\u001b[39m\u001b[34m(cls, s)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msplit\u001b[39m(\u001b[38;5;28mcls\u001b[39m, s):\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/dateutil/parser/_parser.py:189\u001b[39m, in \u001b[36m_timelex.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    190\u001b[39m     token = \u001b[38;5;28mself\u001b[39m.get_token()\n\u001b[32m    191\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "s3_handler = S3Handler()\n",
    "buckets = s3_handler.list_buckets()\n",
    "for bucket in buckets:\n",
    "    print(f\"- {bucket}\")\n",
    "\n",
    "s3_handler.list_objects(\"olkoa-celine\")\n",
    "\n",
    "objects = s3_handler.list_objects(\"olkoa-celine\")\n",
    "for obj in objects:\n",
    "    print(f\"- {obj['key']} ({obj['size']} bytes, modified: {obj['last_modified']})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4051244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 19327 files (3518.13 MB) from olkoa-celine/\n",
      "Downloaded [1/19327]: Archive/1.eml to data/Projects/Projet Demo/Boîte mail de Céline/processed/celine.guyon/Archive/1.eml\n",
      "Downloaded [2/19327]: Archive/10.eml to data/Projects/Projet Demo/Boîte mail de Céline/processed/celine.guyon/Archive/10.eml\n",
      "Downloading: [                                                  ] 0% (1.19 MB / 3518.13 MB)"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m s3_handler = S3Handler()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m buckets = \u001b[43ms3_handler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbucket_name\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43molkoa-celine\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43ms3_prefix\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata/Projects/Projet Demo/Boîte mail de Céline/processed/celine.guyon\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 374\u001b[39m, in \u001b[36mS3Handler.download_directory\u001b[39m\u001b[34m(self, bucket_name, s3_prefix, local_dir)\u001b[39m\n\u001b[32m    365\u001b[39m transfer_config = boto3.s3.transfer.TransferConfig(\n\u001b[32m    366\u001b[39m     use_threads=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    367\u001b[39m     max_concurrency=\u001b[32m10\u001b[39m\n\u001b[32m    368\u001b[39m )\n\u001b[32m    369\u001b[39m transfer = boto3.s3.transfer.S3Transfer(\n\u001b[32m    370\u001b[39m     \u001b[38;5;28mself\u001b[39m.client,\n\u001b[32m    371\u001b[39m     config=transfer_config\n\u001b[32m    372\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m374\u001b[39m \u001b[43mtransfer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbucket_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mkey\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_callback\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m success_count += \u001b[32m1\u001b[39m\n\u001b[32m    380\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[33mDownloaded [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(objects)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj[\u001b[33m'\u001b[39m\u001b[33mkey\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlocal_file_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/boto3/s3/transfer.py:406\u001b[39m, in \u001b[36mS3Transfer.download_file\u001b[39m\u001b[34m(self, bucket, key, filename, extra_args, callback)\u001b[39m\n\u001b[32m    402\u001b[39m future = \u001b[38;5;28mself\u001b[39m._manager.download(\n\u001b[32m    403\u001b[39m     bucket, key, filename, extra_args, subscribers\n\u001b[32m    404\u001b[39m )\n\u001b[32m    405\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m406\u001b[39m     \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[38;5;66;03m# This is for backwards compatibility where when retries are\u001b[39;00m\n\u001b[32m    408\u001b[39m \u001b[38;5;66;03m# exceeded we need to throw the same error from boto3 instead of\u001b[39;00m\n\u001b[32m    409\u001b[39m \u001b[38;5;66;03m# s3transfer's built in RetriesExceededError as current users are\u001b[39;00m\n\u001b[32m    410\u001b[39m \u001b[38;5;66;03m# catching the boto3 one instead of the s3transfer exception to do\u001b[39;00m\n\u001b[32m    411\u001b[39m \u001b[38;5;66;03m# their own retries.\u001b[39;00m\n\u001b[32m    412\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m S3TransferRetriesExceededError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/s3transfer/futures.py:114\u001b[39m, in \u001b[36mTransferFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    113\u001b[39m     \u001b[38;5;28mself\u001b[39m.cancel()\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/s3transfer/futures.py:111\u001b[39m, in \u001b[36mTransferFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mresult\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    107\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    108\u001b[39m         \u001b[38;5;66;03m# Usually the result() method blocks until the transfer is done,\u001b[39;00m\n\u001b[32m    109\u001b[39m         \u001b[38;5;66;03m# however if a KeyboardInterrupt is raised we want want to exit\u001b[39;00m\n\u001b[32m    110\u001b[39m         \u001b[38;5;66;03m# out of this and propagate the exception.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_coordinator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    113\u001b[39m         \u001b[38;5;28mself\u001b[39m.cancel()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/s3transfer/futures.py:267\u001b[39m, in \u001b[36mTransferCoordinator.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    257\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Waits until TransferFuture is done and returns the result\u001b[39;00m\n\u001b[32m    258\u001b[39m \n\u001b[32m    259\u001b[39m \u001b[33;03mIf the TransferFuture succeeded, it will return the result. If the\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[33;03mTransferFuture failed, it will raise the exception associated to the\u001b[39;00m\n\u001b[32m    261\u001b[39m \u001b[33;03mfailure.\u001b[39;00m\n\u001b[32m    262\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    263\u001b[39m \u001b[38;5;66;03m# Doing a wait() with no timeout cannot be interrupted in python2 but\u001b[39;00m\n\u001b[32m    264\u001b[39m \u001b[38;5;66;03m# can be interrupted in python3 so we just wait with the largest\u001b[39;00m\n\u001b[32m    265\u001b[39m \u001b[38;5;66;03m# possible value integer value, which is on the scale of billions of\u001b[39;00m\n\u001b[32m    266\u001b[39m \u001b[38;5;66;03m# years...\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_done_event\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMAXINT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[38;5;66;03m# Once done waiting, raise an exception if present or return the\u001b[39;00m\n\u001b[32m    270\u001b[39m \u001b[38;5;66;03m# final result.\u001b[39;00m\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/threading.py:655\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    653\u001b[39m signaled = \u001b[38;5;28mself\u001b[39m._flag\n\u001b[32m    654\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m655\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/threading.py:355\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    354\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    356\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "s3_handler = S3Handler()\n",
    "buckets = s3_handler.download_directory(\n",
    "    bucket_name = \"olkoa-celine\",\n",
    "    s3_prefix = \"\",\n",
    "    local_dir = \"data/Projects/Projet Demo/Boîte mail de Céline/processed/celine.guyon\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
